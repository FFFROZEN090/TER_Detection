{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7qxYC4A9ark"
   },
   "source": [
    "# Vå½¢é¢†ä¸‰è§’çš®è‚¤æ£€æµ‹ä¸å±€éƒ¨æ‰“ç ç³»ç»Ÿ\n",
    "\n",
    "## åŠŸèƒ½è¯´æ˜\n",
    "\n",
    "æœ¬ç³»ç»Ÿå®ç°å®Œæ•´çš„Vå½¢/äº¤é¢†ä¸‰è§’è£¸éœ²çš®è‚¤è¯†åˆ«ä¸å¤„ç†ç®¡çº¿ï¼š\n",
    "\n",
    "1. **å…³é”®ç‚¹æ£€æµ‹**ï¼šä½¿ç”¨YOLOv8-Poseæ£€æµ‹å·¦å³è‚©å…³é”®ç‚¹\n",
    "2. **ROIæ„é€ **ï¼šåŸºäºè‚©ç‚¹æ„é€ Vå½¢ä¸‰è§’æ„Ÿå…´è¶£åŒºåŸŸ\n",
    "3. **è¯­ä¹‰åˆ†å‰²**ï¼šå¯é€‰ä½¿ç”¨äººä½“/äººè„¸è§£æè¿‡æ»¤è¡£ç‰©åŒºåŸŸ\n",
    "4. **ç²¾ç¡®åˆ†å‰²**ï¼šä½¿ç”¨SAM2å¯¹ä¸‰è§’çš®è‚¤åŒºåŸŸè¿›è¡Œç²¾ç¡®åˆ†å‰²\n",
    "5. **å›¾åƒå¤„ç†**ï¼šæä¾›é©¬èµ›å…‹å’Œè¡£ç‰©é¢œè‰²å¡«å……ä¸¤ç§å¤„ç†æ–¹å¼\n",
    "6. **æ‰¹å¤„ç†**ï¼šæ”¯æŒæ–‡ä»¶å¤¹æ‰¹é‡å¤„ç†\n",
    "\n",
    "### æµç¨‹å›¾\n",
    "```\n",
    "è¾“å…¥å›¾åƒ â†’ å…³é”®ç‚¹æ£€æµ‹ â†’ ä¸‰è§’ROIæ„é€  â†’ [å¯é€‰]è¯­ä¹‰è§£æ â†’ SAM2ç²¾ç¡®åˆ†å‰² â†’ åå¤„ç†(é©¬èµ›å…‹/å¡«å……) â†’ è¾“å‡º\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmSXvHJ_9arm"
   },
   "source": [
    "## 1. é…ç½®å‚æ•°\n",
    "\n",
    "é›†ä¸­é…ç½®æ‰€æœ‰å‚æ•°ï¼Œä¾¿äºè°ƒæ•´å’Œå®éªŒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJV94Y0k9arm",
    "outputId": "8f9e1486-aaae-4241-9194-892679ae9b73"
   },
   "outputs": [],
   "source": "import os\n\n# ç¦ç”¨YOLOè‡ªåŠ¨å®‰è£…ç¼ºå¤±æ¨¡å—\nos.environ[\"ULTRALYTICS_AUTOINSTALL\"] = \"False\"\n\n# å…¨å±€é…ç½®å­—å…¸\nCONFIG = {\n    'models': {\n        'pose': 'yolov8n-pose.pt',  # YOLOv8-Poseæ¨¡å‹ï¼ˆç¨³å®šç‰ˆæœ¬ï¼‰\n        'sam2': 'facebook/sam2-hiera-tiny',  # SAM2æ¨¡å‹ä»HuggingFaceä¸‹è½½\n        'face_parsing': None,  # å¯é€‰: BiSeNet face parsing\n        'human_parsing': None,  # å¯é€‰: SCHP human parsing\n    },\n    'runtime': {\n        'device': 'cuda' if 'CUDA_VISIBLE_DEVICES' in os.environ else 'auto',\n        'precision': 'fp16',  # fp16 for GPU, fp32 for CPU\n    },\n    'processing': {\n        # åŸæœ‰å‚æ•°\n        'roi_chest_down_ratio': 0.28,  # èƒ¸å£å‚è€ƒç‚¹ä¸‹ç§»æ¯”ä¾‹\n        'shoulder_inset_ratio': 0.15,   # è‚©ç‚¹å†…æ”¶æ¯”ä¾‹\n        'mosaic_block': 14,             # é©¬èµ›å…‹å—å¤§å°\n        'blur_kernel': 21,              # é«˜æ–¯æ¨¡ç³Šæ ¸å¤§å°\n        'dilate_for_sampling': 5,       # è¡£ç‰©é‡‡æ ·è†¨èƒ€åŠå¾„\n\n        # æ–°å¢å‚æ•°ï¼šåŒä¸‰è§’ROIå’Œè‚¤è‰²å…ˆéªŒ\n        'neck_up_ratio': 0.12,          # é¢ˆéƒ¨å‘ä¸Šä¸‰è§’æ¯”ä¾‹\n        'color_thresh': 4.0,            # è‚¤è‰²é©¬æ°è·ç¦»é˜ˆå€¼\n        'min_area_px': 20,              # å­ä¸‰è§’æœ€å°é¢ç§¯(åƒç´ )\n        'max_area_ratio': 0.03,         # å­ä¸‰è§’æœ€å¤§é¢ç§¯æ¯”ä¾‹\n        'prefer_up_or_down': 'auto',    # å­ä¸‰è§’åå¥½æ–¹å‘\n        'pose_conf': 0.25,              # å…³é”®ç‚¹æ£€æµ‹ç½®ä¿¡åº¦\n    },\n    'paths': {\n        'data_dir': './data',\n        'out_dir': './outputs',\n        'cache_dir': './hf-cache',\n        'models_dir': './models',\n    }\n}\n\nprint(\"é…ç½®åŠ è½½å®Œæˆ\")\nprint(f\"ä½¿ç”¨æ¨¡å‹: {CONFIG['models']['pose']}\")\nprint(f\"æ•°æ®ç›®å½•: {CONFIG['paths']['data_dir']}\")\nprint(f\"è¾“å‡ºç›®å½•: {CONFIG['paths']['out_dir']}\")\nprint(f\"æ¨¡å‹ç¼“å­˜: {CONFIG['paths']['cache_dir']}\")\nprint(f\"æ–°å¢åŒä¸‰è§’ROIå‚æ•°: neck_up_ratio={CONFIG['processing']['neck_up_ratio']}\")\nprint(f\"æ–°å¢è‚¤è‰²å…ˆéªŒå‚æ•°: color_thresh={CONFIG['processing']['color_thresh']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2shKcqu9arn"
   },
   "source": [
    "## 2. ç¯å¢ƒæ£€æµ‹ä¸ä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_UR-cEz9arn",
    "outputId": "b2ecc3bb-c048-48aa-9022-e0ba246d4f2e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pythonç‰ˆæœ¬: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
      "æ“ä½œç³»ç»Ÿ: Linux 6.1.123+\n",
      "PyTorchç‰ˆæœ¬: 2.8.0+cu126\n",
      "CUDAå¯ç”¨: True\n",
      "CUDAç‰ˆæœ¬: 12.6\n",
      "GPUæ•°é‡: 1\n",
      "GPU 0: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"å®‰è£…PythonåŒ…\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", package])\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"æ£€æµ‹è¿è¡Œç¯å¢ƒ\"\"\"\n",
    "    print(f\"Pythonç‰ˆæœ¬: {sys.version}\")\n",
    "    print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
    "\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "        print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "            print(f\"GPUæ•°é‡: {torch.cuda.device_count()}\")\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        else:\n",
    "            print(\"å°†ä½¿ç”¨CPUæ¨¡å¼\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorchæœªå®‰è£…\")\n",
    "\n",
    "    return torch.cuda.is_available() if 'torch' in locals() else False\n",
    "\n",
    "# æ£€æµ‹ç¯å¢ƒ\n",
    "cuda_available = check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOhM_zdh9aro",
    "outputId": "1a1a594d-1a7a-4fd5-e143-693d3c4c3be5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "å‡çº§ pipï¼ˆå¯é€‰ï¼‰...\n",
      "å®‰è£… Hugging Face ç›¸å…³åŒ…...\n",
      "å®‰è£… PyTorch...\n",
      "å®‰è£…è®¡ç®—æœºè§†è§‰ç›¸å…³åŒ…...\n",
      "å®‰è£… ONNX Runtime...\n",
      "ä¾èµ–å®‰è£…å®Œæˆï¼\n",
      "æç¤ºï¼šå¦‚ç”¨ Hugging Face å¤§æ–‡ä»¶ä¸‹è½½ï¼Œå¯è®¾ç½®ç¯å¢ƒå˜é‡ HF_HUB_ENABLE_HF_TRANSFER=1 ä»¥åŠ é€Ÿã€‚\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, platform, shlex\n",
    "\n",
    "def pip_install(*args):\n",
    "    # é€å‚æ•°ä¼ å…¥ï¼Œé¿å…ç©ºæ ¼è¢«å½“ä½œä¸€ä¸ªâ€œåŒ…åâ€\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", *args])\n",
    "\n",
    "print(\"å‡çº§ pipï¼ˆå¯é€‰ï¼‰...\")\n",
    "try:\n",
    "    pip_install(\"pip\")\n",
    "except Exception as e:\n",
    "    print(\"pip å‡çº§å¤±è´¥ï¼ˆå¿½ç•¥ç»§ç»­ï¼‰ï¼š\", e)\n",
    "\n",
    "print(\"å®‰è£… Hugging Face ç›¸å…³åŒ…...\")\n",
    "pip_install(\"huggingface_hub==0.24.6\", \"hf_transfer==0.1.6\")\n",
    "\n",
    "# å¦‚æœä½ ç¡®å®æœ‰ NVIDIA CUDAï¼ˆLinux/Windows æ­é… CUDA 12.1ï¼‰ï¼ŒæŠŠè¿™ä¸ªå˜é‡è®¾ True\n",
    "cuda_available = False  # â† æŒ‰å®é™…æƒ…å†µæ”¹\n",
    "\n",
    "print(\"å®‰è£… PyTorch...\")\n",
    "if cuda_available:\n",
    "    # ä»… CUDA ä¸»æœºä½¿ç”¨ cu121 æº\n",
    "    pip_install(\"--index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
    "                \"torch==2.3.1\", \"torchvision==0.18.1\")\n",
    "else:\n",
    "    # macOS/CPU é»˜è®¤ç”¨ PyPI\n",
    "    pip_install(\"torch==2.3.1\", \"torchvision==0.18.1\")\n",
    "\n",
    "print(\"å®‰è£…è®¡ç®—æœºè§†è§‰ç›¸å…³åŒ…...\")\n",
    "# å…ˆè£… numpyï¼Œé¿å…æ¥å›é™çº§/å‡çº§\n",
    "pip_install(\"numpy==1.26.4\")\n",
    "\n",
    "# åªä¿ç•™ä¸€ä¸ª OpenCV å‘è¡Œç‰ˆï¼šéœ€è¦ contrib æ¨¡å—å°±ç”¨ä¸‹é¢è¿™ä¸€æ¡\n",
    "pip_install(\"opencv-contrib-python==4.10.0.84\")\n",
    "# å¦‚æœä¸éœ€è¦ contribï¼Œè¯·æ”¹ä¸ºï¼š\n",
    "# pip_install(\"opencv-python==4.10.0.84\")\n",
    "\n",
    "pip_install(\"ultralytics==8.3.20\", \"matplotlib\", \"Pillow\", \"scipy\", \"scikit-image\")\n",
    "\n",
    "print(\"å®‰è£… ONNX Runtime...\")\n",
    "if cuda_available:\n",
    "    pip_install(\"onnxruntime-gpu==1.18.0\")\n",
    "else:\n",
    "    pip_install(\"onnxruntime==1.18.0\")\n",
    "\n",
    "print(\"ä¾èµ–å®‰è£…å®Œæˆï¼\")\n",
    "print(\"æç¤ºï¼šå¦‚ç”¨ Hugging Face å¤§æ–‡ä»¶ä¸‹è½½ï¼Œå¯è®¾ç½®ç¯å¢ƒå˜é‡ HF_HUB_ENABLE_HF_TRANSFER=1 ä»¥åŠ é€Ÿã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5BsCAs59arp"
   },
   "source": [
    "## 3. Hugging Face é•œåƒä¸ç¼“å­˜è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jykKGbWu9arp",
    "outputId": "91f4f94e-3314-4d1b-b13b-05fc4f9ffe96"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ä½¿ç”¨é»˜è®¤Hugging Faceç«¯ç‚¹\n",
      "ç¼“å­˜ç›®å½•: ./hf-cache\n",
      "å·²å¯ç”¨HFä¼ è¾“åŠ é€Ÿ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "# è®¾ç½®Hugging Faceç¯å¢ƒå˜é‡\n",
    "def setup_hf_environment():\n",
    "    \"\"\"è®¾ç½®Hugging Faceç¯å¢ƒå˜é‡\"\"\"\n",
    "    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†é•œåƒç«¯ç‚¹\n",
    "    hf_endpoint = os.environ.get('HF_ENDPOINT') or os.environ.get('HUGGINGFACE_HUB_ENDPOINT')\n",
    "    if hf_endpoint:\n",
    "        print(f\"ä½¿ç”¨Hugging Faceé•œåƒ: {hf_endpoint}\")\n",
    "        os.environ['HUGGINGFACE_HUB_ENDPOINT'] = hf_endpoint\n",
    "    else:\n",
    "        print(\"ä½¿ç”¨é»˜è®¤Hugging Faceç«¯ç‚¹\")\n",
    "\n",
    "    # è®¾ç½®ç¼“å­˜ç›®å½•\n",
    "    cache_dir = os.environ.get('HUGGINGFACE_HUB_CACHE', CONFIG['paths']['cache_dir'])\n",
    "    os.environ['HUGGINGFACE_HUB_CACHE'] = cache_dir\n",
    "    Path(cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"ç¼“å­˜ç›®å½•: {cache_dir}\")\n",
    "\n",
    "    # å¯ç”¨ä¼ è¾“åŠ é€Ÿ\n",
    "    os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
    "    print(\"å·²å¯ç”¨HFä¼ è¾“åŠ é€Ÿ\")\n",
    "\n",
    "    return cache_dir\n",
    "\n",
    "def hf_download(repo_id, local_dir, allow_patterns=None):\n",
    "    \"\"\"ä»Hugging Faceä¸‹è½½æ¨¡å‹\"\"\"\n",
    "    print(f\"ä» {repo_id} ä¸‹è½½åˆ° {local_dir}\")\n",
    "\n",
    "    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨\n",
    "    local_path = Path(local_dir)\n",
    "    if local_path.exists() and any(local_path.iterdir()):\n",
    "        print(f\"æ¨¡å‹å·²å­˜åœ¨äº {local_dir}ï¼Œè·³è¿‡ä¸‹è½½\")\n",
    "        return str(local_path)\n",
    "\n",
    "    try:\n",
    "        local_path.mkdir(parents=True, exist_ok=True)\n",
    "        path = snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            local_dir=local_dir,\n",
    "            allow_patterns=allow_patterns,\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        print(f\"ä¸‹è½½å®Œæˆ: {path}\")\n",
    "\n",
    "        # åˆ—å‡ºä¸‹è½½çš„æ–‡ä»¶\n",
    "        files = list(Path(path).rglob('*'))\n",
    "        print(f\"ä¸‹è½½æ–‡ä»¶æ•°: {len([f for f in files if f.is_file()])}\")\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(f\"ä¸‹è½½å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒ\n",
    "cache_dir = setup_hf_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtL4lagM9arp"
   },
   "source": [
    "## 4. æ¨¡å‹ä¸‹è½½ä¸å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyBhpbHC9arp",
    "outputId": "eca26273-24da-490f-f08a-915d2e46f62c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "å‡†å¤‡ä¸‹è½½SAM2æ¨¡å‹: facebook/sam2-hiera-tiny\n",
      "ä» facebook/sam2-hiera-tiny ä¸‹è½½åˆ° models/sam2\n",
      "æ¨¡å‹å·²å­˜åœ¨äº models/sam2ï¼Œè·³è¿‡ä¸‹è½½\n",
      "SAM2æ¨¡å‹å‡†å¤‡å°±ç»ª\n",
      "YOLOv11-Poseå°†è‡ªåŠ¨ä¸‹è½½\n",
      "è·³è¿‡äººè„¸è§£ææ¨¡å‹ï¼ˆå°†ä»…ä½¿ç”¨ROI+SAM2ï¼‰\n",
      "è·³è¿‡äººä½“è§£ææ¨¡å‹ï¼ˆå°†ä»…ä½¿ç”¨ROI+SAM2ï¼‰\n",
      "\n",
      "æ¨¡å‹å‡†å¤‡å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹ç›®å½•\n",
    "models_dir = Path(CONFIG['paths']['models_dir'])\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ä¸‹è½½SAM2æ¨¡å‹\n",
    "sam2_repo = CONFIG['models']['sam2']\n",
    "sam2_local_dir = models_dir / 'sam2'\n",
    "\n",
    "print(f\"å‡†å¤‡ä¸‹è½½SAM2æ¨¡å‹: {sam2_repo}\")\n",
    "sam2_path = hf_download(sam2_repo, str(sam2_local_dir))\n",
    "\n",
    "if sam2_path:\n",
    "    print(\"SAM2æ¨¡å‹å‡†å¤‡å°±ç»ª\")\n",
    "    CONFIG['models']['sam2_path'] = sam2_path\n",
    "else:\n",
    "    print(\"âŒ SAM2æ¨¡å‹ä¸‹è½½å¤±è´¥\")\n",
    "    CONFIG['models']['sam2_path'] = None\n",
    "\n",
    "# YOLOv11-Poseå°†é€šè¿‡ultralyticsè‡ªåŠ¨ä¸‹è½½\n",
    "print(\"YOLOv11-Poseå°†è‡ªåŠ¨ä¸‹è½½\")\n",
    "\n",
    "# å¯é€‰çš„è§£ææ¨¡å‹ï¼ˆæš‚æ—¶è·³è¿‡ï¼‰\n",
    "if CONFIG['models']['face_parsing']:\n",
    "    print(\"ä¸‹è½½äººè„¸è§£ææ¨¡å‹...\")\n",
    "    # å®ç°äººè„¸è§£ææ¨¡å‹ä¸‹è½½\n",
    "else:\n",
    "    print(\"è·³è¿‡äººè„¸è§£ææ¨¡å‹ï¼ˆå°†ä»…ä½¿ç”¨ROI+SAM2ï¼‰\")\n",
    "\n",
    "if CONFIG['models']['human_parsing']:\n",
    "    print(\"ä¸‹è½½äººä½“è§£ææ¨¡å‹...\")\n",
    "    # å®ç°äººä½“è§£ææ¨¡å‹ä¸‹è½½\n",
    "else:\n",
    "    print(\"è·³è¿‡äººä½“è§£ææ¨¡å‹ï¼ˆå°†ä»…ä½¿ç”¨ROI+SAM2ï¼‰\")\n",
    "\n",
    "print(\"\\næ¨¡å‹å‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWlUffYB9arp"
   },
   "source": [
    "## 5. å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yM7CgwTy9arp",
    "outputId": "bb407b11-211a-4561-bbc2-f52e4fc62957"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "ä½¿ç”¨è®¾å¤‡: cuda\n",
      "åº“å¯¼å…¥å®Œæˆï¼\n",
      "âœ… vneck_fix_utilsæ¨¡å—å·²å¯¼å…¥ï¼šåŒä¸‰è§’ROIã€è‚¤è‰²å…ˆéªŒã€å­ä¸‰è§’é€‰æ‹©åŠŸèƒ½\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# å¯¼å…¥æ–°å¢çš„å·¥å…·æ¨¡å—\n",
    "from vneck_fix_utils import (\n",
    "    build_dual_tri_roi_masks, fit_skin_color_gaussian, filter_mask_by_skincolor,\n",
    "    extract_small_v_subtriangle, split_instances_with_pose\n",
    ")\n",
    "\n",
    "# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ç¡®å®šè®¾å¤‡\n",
    "device = 'cuda' if torch.cuda.is_available() and CONFIG['runtime']['device'] != 'cpu' else 'cpu'\n",
    "CONFIG['runtime']['device'] = device\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "for dir_path in [CONFIG['paths']['data_dir'], CONFIG['paths']['out_dir']]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"åº“å¯¼å…¥å®Œæˆï¼\")\n",
    "print(\"âœ… vneck_fix_utilsæ¨¡å—å·²å¯¼å…¥ï¼šåŒä¸‰è§’ROIã€è‚¤è‰²å…ˆéªŒã€å­ä¸‰è§’é€‰æ‹©åŠŸèƒ½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hs9kVn6M9arq"
   },
   "source": [
    "## 6. å·¥å…·å‡½æ•°å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUsS6LxK9arq",
    "outputId": "a3912111-4c71-419e-e50f-64c0182c20eb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROIæ„é€ å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def build_tri_roi_from_kpts(kpts, img_shape,\n",
    "                           roi_chest_down_ratio=0.28,\n",
    "                           shoulder_inset_ratio=0.15):\n",
    "    \"\"\"ä»å…³é”®ç‚¹æ„é€ ä¸‰è§’å½¢ROI\n",
    "\n",
    "    Args:\n",
    "        kpts: å…³é”®ç‚¹å­—å…¸ï¼ŒåŒ…å«left_shoulder, right_shoulder\n",
    "        img_shape: å›¾åƒå½¢çŠ¶ (H, W)\n",
    "        roi_chest_down_ratio: èƒ¸å£å‚è€ƒç‚¹ä¸‹ç§»æ¯”ä¾‹\n",
    "        shoulder_inset_ratio: è‚©ç‚¹å†…æ”¶æ¯”ä¾‹\n",
    "\n",
    "    Returns:\n",
    "        triangle_points: ä¸‰è§’å½¢ä¸‰ä¸ªé¡¶ç‚¹ [(x1,y1), (x2,y2), (x3,y3)]\n",
    "    \"\"\"\n",
    "    if 'left_shoulder' not in kpts or 'right_shoulder' not in kpts:\n",
    "        return None\n",
    "\n",
    "    left_shoulder = np.array(kpts['left_shoulder'])\n",
    "    right_shoulder = np.array(kpts['right_shoulder'])\n",
    "\n",
    "    # è®¡ç®—è‚©å®½å’Œä¸­ç‚¹\n",
    "    shoulder_width = np.linalg.norm(right_shoulder - left_shoulder)\n",
    "    mid_shoulders = (left_shoulder + right_shoulder) / 2\n",
    "\n",
    "    # èƒ¸å£å‚è€ƒç‚¹ï¼ˆå‘ä¸‹ç§»åŠ¨ï¼‰\n",
    "    chest_point = mid_shoulders + np.array([0, roi_chest_down_ratio * shoulder_width])\n",
    "\n",
    "    # è‚©ç‚¹å†…æ”¶\n",
    "    inset_distance = shoulder_inset_ratio * shoulder_width / 2\n",
    "    left_inset = left_shoulder + (mid_shoulders - left_shoulder) * shoulder_inset_ratio\n",
    "    right_inset = right_shoulder + (mid_shoulders - right_shoulder) * shoulder_inset_ratio\n",
    "\n",
    "    # ä¸‰è§’å½¢é¡¶ç‚¹ï¼šå·¦è‚©å†…æ”¶ç‚¹ã€å³è‚©å†…æ”¶ç‚¹ã€èƒ¸å£ç‚¹\n",
    "    triangle_points = [\n",
    "        tuple(left_inset.astype(int)),\n",
    "        tuple(right_inset.astype(int)),\n",
    "        tuple(chest_point.astype(int))\n",
    "    ]\n",
    "\n",
    "    return triangle_points\n",
    "\n",
    "def mask_from_tri(img_shape, triangle_points):\n",
    "    \"\"\"ä»ä¸‰è§’å½¢é¡¶ç‚¹ç”Ÿæˆæ©è†œ\n",
    "\n",
    "    Args:\n",
    "        img_shape: (H, W) æˆ– (H, W, C)\n",
    "        triangle_points: ä¸‰ä¸ªé¡¶ç‚¹åæ ‡\n",
    "\n",
    "    Returns:\n",
    "        mask: äºŒå€¼æ©è†œï¼Œuint8ç±»å‹\n",
    "    \"\"\"\n",
    "    if triangle_points is None:\n",
    "        return np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    pts = np.array(triangle_points, dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [pts], 255)\n",
    "\n",
    "    return mask\n",
    "\n",
    "print(\"ROIæ„é€ å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4Kj_wfv9arq",
    "outputId": "d42539ff-34c0-45b6-8d9f-fd09c9976f88"
   },
   "outputs": [],
   "source": "def run_yolov8_pose(image, model_path='yolov8n-pose.pt', conf=0.25):\n    \"\"\"ä½¿ç”¨YOLOv8-Poseæ£€æµ‹å¤šäººå…³é”®ç‚¹\n\n    Args:\n        image: è¾“å…¥å›¾åƒ (numpy array, RGBæˆ–BGR)\n        model_path: YOLOv8-Poseæ¨¡å‹è·¯å¾„\n        conf: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼\n\n    Returns:\n        kpts_list: å¤šäººå…³é”®ç‚¹åˆ—è¡¨ [{'nose':..., 'left_shoulder':...}, ...]\n    \"\"\"\n    global pose_model\n\n    # å»¶è¿ŸåŠ è½½æ¨¡å‹\n    if 'pose_model' not in globals():\n        print(\"åŠ è½½YOLOv8-Poseæ¨¡å‹...\")\n        pose_model = YOLO(model_path)\n        pose_model.to(device)\n\n    # ç¡®ä¿è¾“å…¥æ˜¯BGRæ ¼å¼ï¼ˆYOLOæœŸæœ›BGRï¼‰\n    if len(image.shape) == 3 and image.shape[2] == 3:\n        # å¦‚æœæ˜¯RGBï¼Œè½¬æ¢ä¸ºBGR\n        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) if image.max() <= 1.0 or np.mean(image[..., 0]) != np.mean(image[..., 2]) else image\n    else:\n        image_bgr = image\n\n    # è¿è¡Œæ¨ç†\n    results = pose_model.predict(image_bgr, verbose=False, conf=conf)\n\n    kpts_list = []\n    for result in results:\n        if result.keypoints is None:\n            continue\n\n        # å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„äºº\n        for keypoint in result.keypoints.xy:\n            # keypoint: (17,2) COCOæ ¼å¼å…³é”®ç‚¹\n            kp = keypoint.cpu().numpy()\n            kpts_dict = {}\n\n            def add_keypoint(idx, name):\n                if idx < kp.shape[0]:\n                    x, y = float(kp[idx, 0]), float(kp[idx, 1])\n                    # è¿‡æ»¤æ‰(0,0)çš„æ— æ•ˆç‚¹\n                    if x > 0 and y > 0:\n                        kpts_dict[name] = (x, y)\n\n            # COCOå…³é”®ç‚¹ç´¢å¼•æ˜ å°„\n            add_keypoint(0, 'nose')\n            add_keypoint(1, 'left_eye')\n            add_keypoint(2, 'right_eye')\n            add_keypoint(3, 'left_ear')\n            add_keypoint(4, 'right_ear')\n            add_keypoint(5, 'left_shoulder')\n            add_keypoint(6, 'right_shoulder')\n            add_keypoint(7, 'left_elbow')\n            add_keypoint(8, 'right_elbow')\n            add_keypoint(9, 'left_wrist')\n            add_keypoint(10, 'right_wrist')\n            add_keypoint(11, 'left_hip')\n            add_keypoint(12, 'right_hip')\n            add_keypoint(13, 'left_knee')\n            add_keypoint(14, 'right_knee')\n            add_keypoint(15, 'left_ankle')\n            add_keypoint(16, 'right_ankle')\n\n            # åªä¿ç•™æœ‰æœ‰æ•ˆè‚©éƒ¨å…³é”®ç‚¹çš„æ£€æµ‹\n            if 'left_shoulder' in kpts_dict and 'right_shoulder' in kpts_dict:\n                kpts_list.append(kpts_dict)\n\n    return kpts_list\n\ndef run_yolov8_pose_single(image):\n    \"\"\"å…¼å®¹åŸæœ‰å•äººæ¥å£çš„åŒ…è£…å‡½æ•°\"\"\"\n    kpts_list = run_yolov8_pose(image, CONFIG['models']['pose'], CONFIG['processing']['pose_conf'])\n\n    # è¿”å›ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººçš„å…³é”®ç‚¹ï¼Œä¿æŒåŸæ¥å£å…¼å®¹æ€§\n    if len(kpts_list) > 0:\n        return kpts_list[0]\n    else:\n        return {}\n\nprint(\"YOLOv8å¤šäººå…³é”®ç‚¹æ£€æµ‹å‡½æ•°å®šä¹‰å®Œæˆ\")\nprint(\"âœ… æ”¯æŒå¤šäººæ£€æµ‹ï¼šrun_yolov8_pose() è¿”å›å…³é”®ç‚¹åˆ—è¡¨\")\nprint(\"âœ… å…¼å®¹æ€§æ¥å£ï¼šrun_yolov8_pose_single() è¿”å›ç¬¬ä¸€äººå…³é”®ç‚¹\")"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WCpwDXf9arq",
    "outputId": "15386eed-9a97-46e1-8d7c-1c2e65012f5e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "è¯­ä¹‰è§£æå‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def optional_face_human_parsing(image):\n",
    "    \"\"\"å¯é€‰çš„äººè„¸/äººä½“è§£æ\n",
    "\n",
    "    Args:\n",
    "        image: è¾“å…¥å›¾åƒ\n",
    "\n",
    "    Returns:\n",
    "        parse_masks: å­—å…¸ {'skin', 'neck', 'upper', 'scarf'}\n",
    "    \"\"\"\n",
    "    # ç”±äºè§£ææ¨¡å‹å¤æ‚ï¼Œè¿™é‡Œè¿”å›ç©ºæ©è†œ\n",
    "    # åœ¨å®é™…åº”ç”¨ä¸­å¯ä»¥é›†æˆBiSeNetç­‰æ¨¡å‹\n",
    "    h, w = image.shape[:2]\n",
    "    empty_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    return {\n",
    "        'skin': empty_mask.copy(),\n",
    "        'neck': empty_mask.copy(),\n",
    "        'upper': empty_mask.copy(),\n",
    "        'scarf': empty_mask.copy()\n",
    "    }\n",
    "\n",
    "def refine_candidates(tri_mask, parse_masks):\n",
    "    \"\"\"åŸºäºè§£ææ©è†œç»†åŒ–å€™é€‰åŒºåŸŸ\n",
    "\n",
    "    Args:\n",
    "        tri_mask: ä¸‰è§’å½¢ROIæ©è†œ\n",
    "        parse_masks: è§£ææ©è†œå­—å…¸\n",
    "\n",
    "    Returns:\n",
    "        candidate_mask: ç»†åŒ–åçš„å€™é€‰æ©è†œ\n",
    "    \"\"\"\n",
    "    # å¦‚æœæ²¡æœ‰è§£ææ©è†œï¼Œç›´æ¥è¿”å›ä¸‰è§’å½¢ROI\n",
    "    if all(mask.sum() == 0 for mask in parse_masks.values()):\n",
    "        return tri_mask\n",
    "\n",
    "    # çš®è‚¤å€™é€‰ = çš®è‚¤ âˆª è„–å­\n",
    "    skin_candidate = cv2.bitwise_or(parse_masks['skin'], parse_masks['neck'])\n",
    "\n",
    "    # è¡£ç‰©åŒºåŸŸ = ä¸Šè¡£ âˆª å›´å·¾\n",
    "    clothing_mask = cv2.bitwise_or(parse_masks['upper'], parse_masks['scarf'])\n",
    "\n",
    "    # å€™é€‰åŒºåŸŸ = ä¸‰è§’ROI âˆ© çš®è‚¤å€™é€‰ \\ è¡£ç‰©\n",
    "    candidate_mask = cv2.bitwise_and(tri_mask, skin_candidate)\n",
    "    candidate_mask = cv2.bitwise_and(candidate_mask, cv2.bitwise_not(clothing_mask))\n",
    "\n",
    "    return candidate_mask\n",
    "\n",
    "print(\"è¯­ä¹‰è§£æå‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rD8o5mqk9arq",
    "outputId": "8b43f062-6162-4c7e-f3f5-1b83ea361d87"
   },
   "outputs": [],
   "source": "def _farthest_point_sampling(xy, k, seed=0):\n    \"\"\"æœ€è¿œç‚¹é‡‡æ ·ï¼šä»xyä¸­é€‰æ‹©kä¸ªç©ºé—´åˆ†å¸ƒå‡åŒ€çš„ç‚¹\"\"\"\n    rng = np.random.default_rng(seed)\n    m = xy.shape[0]\n    if m == 0:\n        return []\n    if k >= m:\n        return list(range(m))\n    sel = [int(rng.integers(m))]\n    d2 = np.full(m, np.inf)\n    for _ in range(1, k):\n        last = xy[sel[-1]]\n        d2 = np.minimum(d2, np.sum((xy - last)**2, axis=1))\n        sel.append(int(np.argmax(d2)))\n    return sel\n\ndef pick_sam_prompts(candidate_mask, num_pos_points=4, num_neg_points=8, pad=12, seed=0):\n    \"\"\"ç¨³å®šçš„SAM2æç¤ºç‚¹ç”Ÿæˆï¼š\n    - æ­£ç‚¹ï¼šå½¢æ€å­¦è…èš€åçš„maskå†…éƒ¨ï¼Œæœ€è¿œç‚¹é‡‡æ ·ï¼Œé¿å…è´´è¾¹\n    - è´Ÿç‚¹ï¼šmaskè†¨èƒ€å¤–ã€bboxå†…çš„ç¯å½¢åŒºï¼Œé¿å…è¯¯æ£€è¡£ç‰©\n    - bboxï¼šå¯¹æœ€å¤§è¿é€šåŸŸåŠ paddingï¼Œé¿å…å¤ªç´§\n    \n    Args:\n        candidate_mask: å€™é€‰åŒºåŸŸæ©è†œ\n        num_pos_points: æ­£ç‚¹æ•°é‡\n        num_neg_points: è´Ÿç‚¹æ•°é‡\n        pad: bbox paddingåƒç´ æ•°\n        seed: éšæœºç§å­\n    \n    Returns:\n        pos_points: æ­£ç‚¹åˆ—è¡¨ [[x, y], ...]\n        neg_points: è´Ÿç‚¹åˆ—è¡¨ [[x, y], ...]\n        bbox: è¾¹ç•Œæ¡† [x1, y1, x2, y2]\n    \"\"\"\n    H, W = candidate_mask.shape[:2]\n    m = (candidate_mask > 0).astype(np.uint8)\n\n    # æœ€å¤§è¿é€šåŸŸ\n    n, lbl, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n    if n <= 1:\n        return [], [], [0, 0, 1, 1]\n\n    # æŒ‘æœ€å¤§åŒºåŸŸ\n    i = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n    x, y, w, h, area = stats[i]\n    x0 = max(0, x - pad)\n    y0 = max(0, y - pad)\n    x1 = min(W, x + w + pad)\n    y1 = min(H, y + h + pad)\n    bbox = [int(x0), int(y0), int(x1), int(y1)]\n\n    # æ­£ç‚¹ï¼šè…èš€é¿å…è´´è¾¹ï¼Œå†åšæœ€è¿œç‚¹é‡‡æ ·\n    ksz = max(3, int(0.03 * min(W, H)) | 1)  # å¥‡æ•°æ ¸\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksz, ksz))\n    inner = cv2.erode((lbl == i).astype(np.uint8), kernel, 1)\n    if inner.sum() == 0:\n        inner = (lbl == i).astype(np.uint8)  # å›é€€\n\n    ys, xs = np.where(inner > 0)\n    pos_points = []\n    if len(xs) > 0:\n        xy = np.stack([xs, ys], axis=1).astype(np.float32)  # (x,y)\n        sel = _farthest_point_sampling(xy, k=min(num_pos_points, xy.shape[0]), seed=seed)\n        pos_points = xy[sel].astype(np.int32).tolist()\n    else:\n        # å›é€€ï¼šç”¨bboxä¸­å¿ƒ\n        cx, cy = (x0 + x1) // 2, (y0 + y1) // 2\n        pos_points = [[int(cx), int(cy)]]\n\n    # è´Ÿç‚¹ï¼šåœ¨\"bboxå†…ä½†dilate(mask)å¤–\"çš„ç¯å½¢åŒº\n    dil = cv2.dilate((lbl == i).astype(np.uint8), kernel, 1)\n    ring = np.zeros((H, W), np.uint8)\n    ring[y0:y1, x0:x1] = 1\n    ring = (ring & (1 - dil)).astype(np.uint8)\n    nys, nxs = np.where(ring > 0)\n    neg_points = []\n    rng = np.random.default_rng(seed)\n    if len(nxs) > 0:\n        idx = rng.choice(len(nxs), size=min(num_neg_points, len(nxs)), replace=False)\n        neg_points = np.stack([nxs[idx], nys[idx]], axis=1).astype(np.int32).tolist()\n    else:\n        # å›é€€ï¼šåœ¨bboxå››æ¡è¾¹ç­‰é—´éš”æ’’ç‚¹\n        k = max(4, num_neg_points)\n        xs_line = np.linspace(x0, x1 - 1, k, dtype=int)\n        ys_line = np.linspace(y0, y1 - 1, k, dtype=int)\n        edge = set()\n        for xx in xs_line:\n            edge.add((xx, y0))\n            edge.add((xx, y1 - 1))\n        for yy in ys_line:\n            edge.add((x0, yy))\n            edge.add((x1 - 1, yy))\n        neg_points = [list(p) for p in list(edge)[:num_neg_points]]\n\n    return pos_points, neg_points, bbox\n\nprint(\"ç¨³å®šçš„SAM2æç¤ºç”Ÿæˆå‡½æ•°å®šä¹‰å®Œæˆ\")\nprint(\"æ”¹è¿›ï¼šæ­£ç‚¹è…èš€+æœ€è¿œç‚¹é‡‡æ ·ï¼Œè´Ÿç‚¹ç¯å½¢æŠ‘åˆ¶ï¼ŒbboxåŠ padding\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PENUFqr9arr",
    "outputId": "435d939a-0cd7-4423-f3c8-37ac572346a2"
   },
   "outputs": [],
   "source": "# SAM2æ¨¡å‹å…¨å±€ç¼“å­˜\n_SAM2_PREDICTOR = None\n\ndef _get_sam2_predictor():\n    \"\"\"è·å–SAM2é¢„æµ‹å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰\"\"\"\n    global _SAM2_PREDICTOR\n    if _SAM2_PREDICTOR is None:\n        if CONFIG['models']['sam2_path'] is None:\n            print(\"SAM2æ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›None\")\n            return None\n        \n        try:\n            from sam2.build_sam import build_sam2\n            from sam2.sam2_image_predictor import SAM2ImagePredictor\n            \n            sam2_checkpoint = Path(CONFIG['models']['sam2_path']) / \"sam2_hiera_tiny.pt\"\n            model_cfg = \"sam2_hiera_t.yaml\"\n            \n            if not sam2_checkpoint.exists():\n                print(f\"SAM2æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {sam2_checkpoint}\")\n                return None\n            \n            print(\"æ­£åœ¨åŠ è½½SAM2æ¨¡å‹...\")\n            sam2_model = build_sam2(model_cfg, str(sam2_checkpoint), device=device)\n            _SAM2_PREDICTOR = SAM2ImagePredictor(sam2_model)\n            print(\"SAM2æ¨¡å‹åŠ è½½å®Œæˆ\")\n            \n        except ImportError as e:\n            print(f\"SAM2æ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n            return None\n        except Exception as e:\n            print(f\"SAM2æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n            return None\n    \n    return _SAM2_PREDICTOR\n\ndef run_sam2(image_rgb, pos_points, neg_points, bbox, multimask_output=False):\n    \"\"\"ä½¿ç”¨SAM2è¿›è¡Œç²¾ç¡®åˆ†å‰²ï¼ˆä¸å®˜æ–¹APIä¸€è‡´ï¼‰\n    \n    Args:\n        image_rgb: HWC, uint8, RGBæ ¼å¼å›¾åƒ\n        pos_points: æ­£ç‚¹åˆ—è¡¨ [[x,y], ...] åƒç´ åæ ‡\n        neg_points: è´Ÿç‚¹åˆ—è¡¨ [[x,y], ...] åƒç´ åæ ‡  \n        bbox: è¾¹ç•Œæ¡† [x1,y1,x2,y2] åƒç´ åæ ‡\n        multimask_output: æ˜¯å¦è¾“å‡ºå¤šä¸ªmask\n    \n    Returns:\n        final_mask: æœ€ç»ˆåˆ†å‰²æ©è†œ\n    \"\"\"\n    predictor = _get_sam2_predictor()\n    \n    if predictor is None:\n        print(\"SAM2ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–åˆ†å‰²\")\n        return simple_segmentation_fallback(image_rgb, pos_points, neg_points, bbox)\n    \n    try:\n        # è®¾ç½®å›¾åƒ\n        predictor.set_image(image_rgb)\n        \n        # å‡†å¤‡æç¤ºç‚¹\n        pts = np.array(pos_points + neg_points, dtype=np.float32)\n        lbl = np.array([1] * len(pos_points) + [0] * len(neg_points), dtype=np.int32)\n        \n        # è½¬æ¢ä¸ºSAM2è¦æ±‚çš„å½¢çŠ¶\n        pts = None if pts.size == 0 else pts[None, :, :]  # (1,N,2)\n        lbl = None if lbl.size == 0 else lbl[None, :]     # (1,N)\n        box = None\n        if bbox is not None and len(bbox) == 4:\n            box = np.array(bbox, dtype=np.float32)[None, :]  # (1,4)\n        \n        # è¿è¡Œé¢„æµ‹\n        masks, scores, logits = predictor.predict(\n            point_coords=pts,\n            point_labels=lbl, \n            box=box,\n            multimask_output=multimask_output,\n            normalize_coords=False  # é‡è¦ï¼šä½¿ç”¨åƒç´ åæ ‡\n        )\n        \n        # å–æœ€é«˜åˆ†çš„mask\n        if masks is None or len(masks) == 0:\n            return np.zeros(image_rgb.shape[:2], np.uint8)\n        \n        i = int(np.argmax(scores))\n        mask = masks[i].astype(np.uint8) * 255\n        \n        return mask\n        \n    except Exception as e:\n        print(f\"SAM2é¢„æµ‹å¤±è´¥: {e}\")\n        return simple_segmentation_fallback(image_rgb, pos_points, neg_points, bbox)\n\ndef simple_segmentation_fallback(image_rgb, pos_points, neg_points, bbox):\n    \"\"\"ç®€åŒ–çš„åˆ†å‰²å›é€€æ–¹æ¡ˆ\"\"\"\n    if len(pos_points) == 0:\n        return np.zeros(image_rgb.shape[:2], dtype=np.uint8)\n    \n    # åŸºäºæ­£ç‚¹å‘¨å›´åŒºåŸŸçš„ç®€å•åˆ†å‰²\n    mask = np.zeros(image_rgb.shape[:2], dtype=np.uint8)\n    \n    # åœ¨æ¯ä¸ªæ­£ç‚¹å‘¨å›´åˆ›å»ºåœ†å½¢åŒºåŸŸ\n    for point in pos_points:\n        x, y = int(point[0]), int(point[1])\n        cv2.circle(mask, (x, y), 25, 255, -1)\n    \n    # å¦‚æœæœ‰bboxï¼Œçº¦æŸåœ¨bboxå†…\n    if bbox and len(bbox) == 4:\n        x1, y1, x2, y2 = bbox\n        mask_bbox = np.zeros_like(mask)\n        mask_bbox[y1:y2, x1:x2] = 255\n        mask = cv2.bitwise_and(mask, mask_bbox)\n    \n    return mask\n\nprint(\"ä¸å®˜æ–¹APIä¸€è‡´çš„SAM2åˆ†å‰²å‡½æ•°å®šä¹‰å®Œæˆ\")\nprint(\"æ”¹è¿›ï¼šåƒç´ åæ ‡+æ­£ç¡®shapeï¼Œæç¤ºç‚¹(1,N,2)ï¼Œæ ‡ç­¾(1,N)ï¼Œbbox(1,4)\")"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhR2WQsF9arr",
    "outputId": "b7bb4f94-ba6d-4a14-b31c-6326cce160c1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "é©¬èµ›å…‹å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def mosaic_region(image, mask, block_size=14):\n",
    "    \"\"\"å¯¹æŒ‡å®šåŒºåŸŸè¿›è¡Œé©¬èµ›å…‹å¤„ç†\n",
    "\n",
    "    Args:\n",
    "        image: è¾“å…¥å›¾åƒ\n",
    "        mask: å¤„ç†åŒºåŸŸæ©è†œ\n",
    "        block_size: é©¬èµ›å…‹å—å¤§å°\n",
    "\n",
    "    Returns:\n",
    "        result: å¤„ç†åçš„å›¾åƒ\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "\n",
    "    # æ‰¾åˆ°æ©è†œåŒºåŸŸçš„è¾¹ç•Œæ¡†\n",
    "    coords = np.column_stack(np.where(mask > 0))\n",
    "    if len(coords) == 0:\n",
    "        return result\n",
    "\n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0)\n",
    "\n",
    "    # æå–ROI\n",
    "    roi = result[y_min:y_max+1, x_min:x_max+1]\n",
    "    roi_mask = mask[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    if roi.size == 0:\n",
    "        return result\n",
    "\n",
    "    # ä¸‹é‡‡æ ·å†ä¸Šé‡‡æ ·å®ç°é©¬èµ›å…‹æ•ˆæœ\n",
    "    h, w = roi.shape[:2]\n",
    "    small_h, small_w = max(1, h // block_size), max(1, w // block_size)\n",
    "\n",
    "    small_roi = cv2.resize(roi, (small_w, small_h), interpolation=cv2.INTER_LINEAR)\n",
    "    mosaic_roi = cv2.resize(small_roi, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # åº”ç”¨æ©è†œ\n",
    "    roi_mask_3ch = np.stack([roi_mask] * 3, axis=-1) / 255.0\n",
    "    result[y_min:y_max+1, x_min:x_max+1] = roi * (1 - roi_mask_3ch) + mosaic_roi * roi_mask_3ch\n",
    "\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "def blur_region(image, mask, kernel_size=21):\n",
    "    \"\"\"å¯¹æŒ‡å®šåŒºåŸŸè¿›è¡Œé«˜æ–¯æ¨¡ç³Šå¤„ç†\"\"\"\n",
    "    result = image.copy()\n",
    "\n",
    "    # ç¡®ä¿kernel_sizeä¸ºå¥‡æ•°\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "\n",
    "    # å¯¹æ•´ä¸ªå›¾åƒè¿›è¡Œæ¨¡ç³Š\n",
    "    blurred = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    # ä½¿ç”¨æ©è†œæ··åˆæ¨¡ç³Šå’ŒåŸå›¾\n",
    "    mask_3ch = np.stack([mask] * 3, axis=-1) / 255.0\n",
    "    result = image * (1 - mask_3ch) + blurred * mask_3ch\n",
    "\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "print(\"é©¬èµ›å…‹å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D76MPLlP9arr",
    "outputId": "4c0a4ecb-6665-4aab-9f85-a16c6ae81283"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "é¢œè‰²å¡«å……å‡½æ•°å®šä¹‰å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "def fill_with_cloth_color(image, mask, dilate_radius=5):\n",
    "    \"\"\"ç”¨è¡£ç‰©é¢œè‰²å¡«å……æŒ‡å®šåŒºåŸŸ\n",
    "\n",
    "    Args:\n",
    "        image: è¾“å…¥å›¾åƒ\n",
    "        mask: å¡«å……åŒºåŸŸæ©è†œ\n",
    "        dilate_radius: è¡£ç‰©é‡‡æ ·è†¨èƒ€åŠå¾„\n",
    "\n",
    "    Returns:\n",
    "        result: å¤„ç†åçš„å›¾åƒ\n",
    "    \"\"\"\n",
    "    result = image.copy()\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        return result\n",
    "\n",
    "    # è†¨èƒ€æ©è†œä»¥è·å–å‘¨å›´è¡£ç‰©åŒºåŸŸ\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n",
    "                                      (dilate_radius*2+1, dilate_radius*2+1))\n",
    "    dilated_mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "    # è¡£ç‰©é‡‡æ ·åŒºåŸŸ = è†¨èƒ€åŒºåŸŸ - åŸå§‹æ©è†œ\n",
    "    cloth_region = cv2.bitwise_and(dilated_mask, cv2.bitwise_not(mask))\n",
    "\n",
    "    # ä»è¡£ç‰©åŒºåŸŸé‡‡æ ·é¢œè‰²\n",
    "    cloth_pixels = image[cloth_region > 0]\n",
    "    if len(cloth_pixels) > 0:\n",
    "        # è®¡ç®—ä¸­ä½è‰²\n",
    "        median_color = np.median(cloth_pixels, axis=0).astype(np.uint8)\n",
    "\n",
    "        # å¡«å……åŒºåŸŸ\n",
    "        result[mask > 0] = median_color\n",
    "\n",
    "        try:\n",
    "            # ä½¿ç”¨æ³Šæ¾èåˆè¿›è¡Œæ— ç¼åˆæˆ\n",
    "            center = tuple(np.mean(np.column_stack(np.where(mask > 0)), axis=0).astype(int)[::-1])\n",
    "            result = cv2.seamlessClone(result, image, mask, center, cv2.NORMAL_CLONE)\n",
    "        except:\n",
    "            # å¦‚æœæ³Šæ¾èåˆå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„è¾¹ç•Œæ¨¡ç³Š\n",
    "            mask_blur = cv2.GaussianBlur(mask.astype(np.float32), (5, 5), 0) / 255.0\n",
    "            mask_blur = np.stack([mask_blur] * 3, axis=-1)\n",
    "            result = image * (1 - mask_blur) + result * mask_blur\n",
    "\n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "print(\"é¢œè‰²å¡«å……å‡½æ•°å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27SiEnMI9arr"
   },
   "source": [
    "## 7. ä¸»å¤„ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYs69TSn9arr",
    "outputId": "05aef135-d28b-43b0-e905-c65a07f92095"
   },
   "outputs": [],
   "source": "def process_one_person(image_bgr, kpts, person_id=0):\n    \"\"\"å¤„ç†å•ä¸ªäººçš„Vé¢†çš®è‚¤æ£€æµ‹\n\n    Args:\n        image_bgr: BGRæ ¼å¼å›¾åƒ\n        kpts: è¯¥äººçš„å…³é”®ç‚¹å­—å…¸\n        person_id: äººå‘˜IDï¼ˆç”¨äºè°ƒè¯•ï¼‰\n\n    Returns:\n        final_mask: æœ€ç»ˆå¤„ç†æ©è†œ\n        debug_info: è°ƒè¯•ä¿¡æ¯\n    \"\"\"\n    h, w = image_bgr.shape[:2]\n\n    # 1. æ„é€ åŒä¸‰è§’ROIï¼ˆèƒ¸å£å‘ä¸‹ + é¢ˆéƒ¨å‘ä¸Šï¼‰\n    try:\n        m_down, m_up, tri_down, tri_up = build_dual_tri_roi_masks(\n            kpts, image_bgr.shape,\n            CONFIG['processing']['roi_chest_down_ratio'],\n            CONFIG['processing']['neck_up_ratio'],\n            CONFIG['processing']['shoulder_inset_ratio']\n        )\n        # åˆå¹¶åŒä¸‰è§’ROI\n        tri_mask = (m_down | m_up).astype(np.uint8)\n    except:\n        print(f\"æ— æ³•æ„é€ åŒä¸‰è§’ROI (person {person_id})\")\n        return np.zeros((h, w), np.uint8), {}\n\n    # 2. è‚¤è‰²å…ˆéªŒæ‹Ÿåˆ\n    mu, cov, face_mask = fit_skin_color_gaussian(image_bgr, kpts)\n\n    # 3. ç”ŸæˆSAM2æç¤ºç‚¹ï¼ˆåœ¨åŒä¸‰è§’ROIå†…ï¼‰\n    pos_points, neg_points, bbox = pick_sam_prompts(tri_mask)\n\n    # 4. SAM2ç²¾ç¡®åˆ†å‰²\n    mask_sam = run_sam2(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB), pos_points, neg_points, bbox)\n\n    # 5. çº¦æŸSAM2ç»“æœåœ¨åŒä¸‰è§’ROIå†…\n    mask_sam = (mask_sam & tri_mask).astype(np.uint8)\n\n    if mask_sam.sum() == 0:\n        print(f\"SAM2åˆ†å‰²ç»“æœä¸ºç©º (person {person_id})\")\n        return np.zeros((h, w), np.uint8), {}\n\n    # 6. å­ä¸‰è§’é€‰æ‹©ï¼ˆå±‚å Vé¢†çš„å°å€’ä¸‰è§’ï¼‰\n    final_mask = extract_small_v_subtriangle(\n        image_bgr, kpts, roi_mask=mask_sam, mu=mu, cov=cov,\n        color_thresh=CONFIG['processing']['color_thresh'],\n        min_area_px=CONFIG['processing']['min_area_px'],\n        max_area_ratio=CONFIG['processing']['max_area_ratio'],\n        prefer_up_or_down=CONFIG['processing']['prefer_up_or_down']\n    )\n\n    debug_info = {\n        'tri_mask': tri_mask,\n        'mask_sam': mask_sam,\n        'face_mask': face_mask,\n        'mu': mu,\n        'cov': cov,\n        'tri_down': tri_down,\n        'tri_up': tri_up\n    }\n\n    return final_mask, debug_info\n\ndef process_one(image_path, output_dir, mode='both'):\n    \"\"\"å¤„ç†å•å¼ å›¾åƒï¼ˆæ”¯æŒå¤šäººï¼‰\n\n    Args:\n        image_path: è¾“å…¥å›¾åƒè·¯å¾„\n        output_dir: è¾“å‡ºç›®å½•\n        mode: å¤„ç†æ¨¡å¼ 'mosaic'/'fill'/'both'\n\n    Returns:\n        success: æ˜¯å¦å¤„ç†æˆåŠŸ\n        results: ç»“æœå­—å…¸\n    \"\"\"\n    try:\n        # è¯»å–å›¾åƒ\n        image = cv2.imread(str(image_path))\n        if image is None:\n            print(f\"æ— æ³•è¯»å–å›¾åƒ: {image_path}\")\n            return False, {}\n\n        # ä¿æŒBGRæ ¼å¼ç”¨äºå¤„ç†ï¼ŒRGBæ ¼å¼ç”¨äºæ˜¾ç¤º\n        image_bgr = image.copy()\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        h, w = image_bgr.shape[:2]\n\n        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰\n        stem = Path(image_path).stem\n\n        print(f\"å¤„ç†å›¾åƒ: {image_path.name} ({w}x{h})\")\n\n        # 1. å¤šäººå…³é”®ç‚¹æ£€æµ‹\n        all_kpts = run_yolov8_pose(image_rgb, CONFIG['models']['pose'], CONFIG['processing']['pose_conf'])\n\n        if len(all_kpts) == 0:\n            print(f\"æœªæ£€æµ‹åˆ°ä»»ä½•äººï¼Œè·³è¿‡: {image_path.name}\")\n            return False, {'reason': 'no_person_detected'}\n\n        print(f\"æ£€æµ‹åˆ° {len(all_kpts)} ä¸ªäºº\")\n\n        # 2. é€äººå¤„ç†å¹¶åˆå¹¶æ©è†œ\n        final_union = np.zeros((h, w), np.uint8)\n        all_debug_info = []\n        processed_count = 0\n\n        for i, kpts in enumerate(all_kpts):\n            print(f\"  å¤„ç†ç¬¬ {i+1} äºº...\")\n\n            # æ£€æŸ¥å¿…è¦çš„å…³é”®ç‚¹\n            if 'left_shoulder' not in kpts or 'right_shoulder' not in kpts:\n                print(f\"    ç¼ºå°‘è‚©éƒ¨å…³é”®ç‚¹ï¼Œè·³è¿‡ç¬¬ {i+1} äºº\")\n                continue\n\n            # å¤„ç†å•äºº\n            person_mask, debug_info = process_one_person(image_bgr, kpts, i)\n\n            if person_mask.sum() > 0:\n                final_union |= person_mask\n                processed_count += 1\n                print(f\"    ç¬¬ {i+1} äººå¤„ç†å®Œæˆï¼Œæ©è†œåƒç´ : {person_mask.sum()}\")\n            else:\n                print(f\"    ç¬¬ {i+1} äººæ— æœ‰æ•ˆæ©è†œ\")\n\n            all_debug_info.append(debug_info)\n\n        if final_union.sum() == 0:\n            print(f\"æ‰€æœ‰äººå¤„ç†åæ©è†œå‡ä¸ºç©ºï¼Œè·³è¿‡: {image_path.name}\")\n            return False, {'reason': 'no_final_mask'}\n\n        print(f\"æˆåŠŸå¤„ç† {processed_count}/{len(all_kpts)} äººï¼Œåˆå¹¶æ©è†œåƒç´ : {final_union.sum()}\")\n\n        # 3. å›¾åƒåå¤„ç†ï¼ˆä½¿ç”¨åˆå¹¶åçš„æ©è†œï¼‰\n        results = {\n            'all_kpts': all_kpts,\n            'processed_count': processed_count,\n            'total_persons': len(all_kpts),\n            'debug_info': all_debug_info\n        }\n\n        # ä¿å­˜æ©è†œ\n        mask_path = output_dir / f\"{stem}_mask.png\"\n        cv2.imwrite(str(mask_path), final_union)\n        results['mask_path'] = mask_path\n\n        # é©¬èµ›å…‹å¤„ç†\n        if mode in ['mosaic', 'both']:\n            mosaic_result = mosaic_region(\n                image_rgb, final_union,\n                CONFIG['processing']['mosaic_block']\n            )\n            mosaic_path = output_dir / f\"{stem}_mosaic.jpg\"\n            cv2.imwrite(str(mosaic_path), cv2.cvtColor(mosaic_result, cv2.COLOR_RGB2BGR))\n            results['mosaic_path'] = mosaic_path\n\n        # é¢œè‰²å¡«å……å¤„ç†\n        if mode in ['fill', 'both']:\n            fill_result = fill_with_cloth_color(\n                image_rgb, final_union,\n                CONFIG['processing']['dilate_for_sampling']\n            )\n            fill_path = output_dir / f\"{stem}_fill.jpg\"\n            cv2.imwrite(str(fill_path), cv2.cvtColor(fill_result, cv2.COLOR_RGB2BGR))\n            results['fill_path'] = fill_path\n\n        # ä¿å­˜å¯è§†åŒ–å åŠ å›¾ï¼ˆå¤šäººï¼‰\n        overlay = image_rgb.copy()\n        overlay[final_union > 0] = [255, 0, 0]  # çº¢è‰²æ ‡è®°æœ€ç»ˆæ©è†œ\n        overlay = cv2.addWeighted(image_rgb, 0.7, overlay, 0.3, 0)\n\n        # ç»˜åˆ¶æ‰€æœ‰äººçš„å…³é”®ç‚¹å’Œä¸‰è§’å½¢\n        colors = [(0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]\n        for i, (kpts, debug_info) in enumerate(zip(all_kpts, all_debug_info)):\n            color = colors[i % len(colors)]\n\n            # ç»˜åˆ¶è‚©éƒ¨å…³é”®ç‚¹\n            if 'left_shoulder' in kpts:\n                cv2.circle(overlay, tuple(map(int, kpts['left_shoulder'])), 5, color, -1)\n            if 'right_shoulder' in kpts:\n                cv2.circle(overlay, tuple(map(int, kpts['right_shoulder'])), 5, color, -1)\n\n            # ç»˜åˆ¶åŒä¸‰è§’ROI\n            if 'tri_down' in debug_info and debug_info['tri_down'] is not None:\n                cv2.polylines(overlay, [debug_info['tri_down']], True, color, 2)\n            if 'tri_up' in debug_info and debug_info['tri_up'] is not None:\n                cv2.polylines(overlay, [debug_info['tri_up']], True, color, 1)\n\n        overlay_path = output_dir / f\"{stem}_overlay.jpg\"\n        cv2.imwrite(str(overlay_path), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n        results['overlay_path'] = overlay_path\n\n        print(f\"å¤„ç†å®Œæˆ: {image_path.name}\")\n        return True, results\n\n    except Exception as e:\n        print(f\"å¤„ç†å¤±è´¥ {image_path.name}: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False, {'reason': 'exception', 'error': str(e)}\n\nprint(\"å¤šäººå¤„ç†ä¸»å‡½æ•°å®šä¹‰å®Œæˆ\")\nprint(\"æ”¯æŒå¤šäººæ£€æµ‹å’Œå¤„ç†\")\nprint(\"é›†æˆåŒä¸‰è§’ROI + è‚¤è‰²å…ˆéªŒ + å­ä¸‰è§’é€‰æ‹©\")\nprint(\"ä¿æŒåŸæœ‰æ¥å£å…¼å®¹æ€§\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84WLzLWq9arr"
   },
   "source": [
    "## 8. åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LY9uHhup9ars",
    "outputId": "6dd0954a-00b1-4447-dcc9-011a9b7d2686"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "æ•°æ®ç›®å½•: /content/data\n",
      "è¾“å‡ºç›®å½•: /content/outputs\n",
      "\n",
      "æ‰¾åˆ° 7 ä¸ªå›¾åƒæ–‡ä»¶:\n",
      "  - f7f1df83-caf0-4534-8588-a12f6bd1d7ad.png\n",
      "  - 4d3434e8-5749-4300-9e16-64739da5bc63.png\n",
      "  - 2cded38f-22db-475a-8b30-c98ebb8a7d5f.png\n",
      "  - e475ad54-5b2a-4c0a-b31e-41a9281aea37.png\n",
      "  - e5932997-651d-4ebf-a6b0-9f56d30fda24.png\n",
      "  - 34ff9167-1f56-48b6-a6cd-5ace989fbbdd.png\n",
      "  - 2e31357b-ac5d-4bdf-a7d0-8eaa29ee30b9.png\n",
      "\n",
      "âœ… å‡†å¤‡å¤„ç† 7 ä¸ªå›¾åƒæ–‡ä»¶\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# åˆ›å»ºå¿…è¦çš„ç›®å½•\n",
    "data_dir = Path(CONFIG['paths']['data_dir'])\n",
    "output_dir = Path(CONFIG['paths']['out_dir'])\n",
    "\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"æ•°æ®ç›®å½•: {data_dir.absolute()}\")\n",
    "print(f\"è¾“å‡ºç›®å½•: {output_dir.absolute()}\")\n",
    "\n",
    "# æ£€æŸ¥æ•°æ®ç›®å½•ä¸­çš„å›¾åƒæ–‡ä»¶\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "image_files = []\n",
    "for ext in image_extensions:\n",
    "    image_files.extend(list(data_dir.glob(f'*{ext}')))\n",
    "    image_files.extend(list(data_dir.glob(f'*{ext.upper()}')))\n",
    "\n",
    "print(f\"\\næ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶:\")\n",
    "for img_file in image_files:\n",
    "    print(f\"  - {img_file.name}\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"\\nğŸ“ è¯·å°†æµ‹è¯•å›¾åƒæ”¾å…¥ data/ ç›®å½•\")\n",
    "    print(\"æ”¯æŒæ ¼å¼: .jpg, .jpeg, .png, .bmp\")\n",
    "else:\n",
    "    print(f\"\\nâœ… å‡†å¤‡å¤„ç† {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RqC1Nf49ars"
   },
   "source": [
    "## 9. æ–‡ä»¶ä¸Šä¼ å•å…ƒæ ¼\n",
    "\n",
    "è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼æ¥ä¸Šä¼ æµ‹è¯•å›¾åƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "114937d028444a01b0b415c72b9a756d",
      "f804620a9c674a3e9a272fee9a9fad0a",
      "fd90dde495114358933572347b2895d2"
     ]
    },
    "id": "dMrqrABB9ars",
    "outputId": "717024cb-b2ea-40ab-ae66-d2157a5e71bf"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "FileUpload(value={}, accept='image/*', description='é€‰æ‹©å›¾åƒæ–‡ä»¶', multiple=True)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "114937d028444a01b0b415c72b9a756d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ï¼ˆéœ€è¦åœ¨æ”¯æŒçš„ç¯å¢ƒä¸­è¿è¡Œï¼‰\n",
    "try:\n",
    "    from IPython.display import display, HTML\n",
    "    import ipywidgets as widgets\n",
    "    from ipywidgets import FileUpload\n",
    "\n",
    "    # åˆ›å»ºæ–‡ä»¶ä¸Šä¼ æ§ä»¶\n",
    "    uploader = FileUpload(\n",
    "        accept='image/*',\n",
    "        multiple=True,\n",
    "        description='é€‰æ‹©å›¾åƒæ–‡ä»¶'\n",
    "    )\n",
    "\n",
    "    def on_upload(change):\n",
    "        \"\"\"å¤„ç†æ–‡ä»¶ä¸Šä¼ \"\"\"\n",
    "        for filename, file_info in uploader.value.items():\n",
    "            content = file_info['content']\n",
    "            # ä¿å­˜åˆ°dataç›®å½•\n",
    "            file_path = data_dir / filename\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(content)\n",
    "            print(f\"å·²ä¿å­˜: {filename}\")\n",
    "\n",
    "    uploader.observe(on_upload, names='value')\n",
    "    display(uploader)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"ğŸ“ è¯·æ‰‹åŠ¨å°†å›¾åƒæ–‡ä»¶å¤åˆ¶åˆ° data/ ç›®å½•\")\n",
    "    print(\"æˆ–è€…ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸Šä¼ :\")\n",
    "    print(\"!cp /path/to/your/images/* ./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvCmJifz9ars"
   },
   "source": [
    "## 10. å•å›¾æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOD5rONj9ars",
    "outputId": "5b5a71d2-2c53-4e8c-ac41-b81dd419d647"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "æ¼”ç¤ºå›¾åƒ: f7f1df83-caf0-4534-8588-a12f6bd1d7ad.png\n",
      "å¤„ç†å›¾åƒ: f7f1df83-caf0-4534-8588-a12f6bd1d7ad.png (324x414)\n",
      "åŠ è½½YOLO11-Poseæ¨¡å‹...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.97M/5.97M [00:00<00:00, 219MB/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING âš ï¸ yolo11n-pose.pt appears to require 'torch.utils.serialization', which is not in Ultralytics requirements.\n",
      "AutoInstall will run now for 'torch.utils.serialization' but this feature will be removed in the future.\n",
      "Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official Ultralytics model, i.e. 'yolo predict model=yolov8n.pt'\n",
      "âŒ å¤„ç†å¤±è´¥ f7f1df83-caf0-4534-8588-a12f6bd1d7ad.png: No module named 'torch.utils.serialization'\n",
      "âŒ æ¼”ç¤ºå¤„ç†å¤±è´¥: exception\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 837, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/patches.py\", line 86, in torch_load\n",
      "    return _torch_load(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1475, in load\n",
      "ModuleNotFoundError: No module named 'torch.utils.serialization'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipython-input-621168175.py\", line 96, in process_one\n",
      "    all_kpts = run_yolo11_pose(image_rgb, CONFIG['models']['pose'], CONFIG['processing']['pose_conf'])\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipython-input-3339281033.py\", line 17, in run_yolo11_pose\n",
      "    pose_model = YOLO(model_path)\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/model.py\", line 23, in __init__\n",
      "    super().__init__(model=model, task=task, verbose=verbose)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 145, in __init__\n",
      "    self._load(model, task=task)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 285, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 910, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 857, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/patches.py\", line 86, in torch_load\n",
      "    return _torch_load(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1475, in load\n",
      "ModuleNotFoundError: No module named 'torch.utils.serialization'\n"
     ]
    }
   ],
   "source": [
    "# é€‰æ‹©ç¬¬ä¸€ä¸ªå›¾åƒè¿›è¡Œå¤šäººæ¼”ç¤º\n",
    "demo_image_path = None\n",
    "if image_files:\n",
    "    demo_image_path = image_files[0]\n",
    "    print(f\"æ¼”ç¤ºå›¾åƒ: {demo_image_path.name}\")\n",
    "\n",
    "    # å¤„ç†å•å¼ å›¾åƒï¼ˆæ”¯æŒå¤šäººï¼‰\n",
    "    success, results = process_one(demo_image_path, output_dir, mode='both')\n",
    "\n",
    "    if success:\n",
    "        print(f\"\\nâœ… å¤šäººæ¼”ç¤ºå¤„ç†æˆåŠŸï¼\")\n",
    "        print(f\"æ£€æµ‹åˆ° {results['total_persons']} äººï¼ŒæˆåŠŸå¤„ç† {results['processed_count']} äºº\")\n",
    "\n",
    "        # æ˜¾ç¤ºç»“æœ\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # åŸå§‹å›¾åƒ\n",
    "        original = cv2.imread(str(demo_image_path))\n",
    "        original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "        axes[0].imshow(original)\n",
    "        axes[0].set_title('åŸå§‹å›¾åƒ')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # æ©è†œ\n",
    "        if 'mask_path' in results:\n",
    "            mask = cv2.imread(str(results['mask_path']), cv2.IMREAD_GRAYSCALE)\n",
    "            axes[1].imshow(mask, cmap='gray')\n",
    "            axes[1].set_title(f'æœ€ç»ˆæ©è†œ ({results[\"processed_count\"]}äºº)')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "        # å¯è§†åŒ–å åŠ ï¼ˆå¤šäººå…³é”®ç‚¹+åŒä¸‰è§’ROIï¼‰\n",
    "        if 'overlay_path' in results:\n",
    "            overlay = cv2.imread(str(results['overlay_path']))\n",
    "            overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "            axes[2].imshow(overlay)\n",
    "            axes[2].set_title('å¤šäººå…³é”®ç‚¹+åŒä¸‰è§’ROI+æ©è†œ')\n",
    "            axes[2].axis('off')\n",
    "\n",
    "        # é©¬èµ›å…‹ç»“æœ\n",
    "        if 'mosaic_path' in results:\n",
    "            mosaic = cv2.imread(str(results['mosaic_path']))\n",
    "            mosaic = cv2.cvtColor(mosaic, cv2.COLOR_BGR2RGB)\n",
    "            axes[3].imshow(mosaic)\n",
    "            axes[3].set_title('é©¬èµ›å…‹å¤„ç†')\n",
    "            axes[3].axis('off')\n",
    "\n",
    "        # é¢œè‰²å¡«å……ç»“æœ\n",
    "        if 'fill_path' in results:\n",
    "            fill = cv2.imread(str(results['fill_path']))\n",
    "            fill = cv2.cvtColor(fill, cv2.COLOR_BGR2RGB)\n",
    "            axes[4].imshow(fill)\n",
    "            axes[4].set_title('è¡£ç‰©é¢œè‰²å¡«å……')\n",
    "            axes[4].axis('off')\n",
    "\n",
    "        # éšè—å¤šä½™çš„å­å›¾\n",
    "        axes[5].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'å¤šäººVé¢†çš®è‚¤æ£€æµ‹æ¼”ç¤º - å¤„ç†{results[\"processed_count\"]}/{results[\"total_persons\"]}äºº',\n",
    "                    fontsize=14, y=0.98)\n",
    "        plt.show()\n",
    "\n",
    "        # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡\n",
    "        print(f\"\\nğŸ“Š å¤„ç†ç»Ÿè®¡:\")\n",
    "        print(f\"  æ€»æ£€æµ‹äººæ•°: {results['total_persons']}\")\n",
    "        print(f\"  æˆåŠŸå¤„ç†: {results['processed_count']}\")\n",
    "        print(f\"  æœ€ç»ˆæ©è†œåƒç´ : {cv2.imread(str(results['mask_path']), cv2.IMREAD_GRAYSCALE).sum() if 'mask_path' in results else 0}\")\n",
    "\n",
    "        print(f\"\\nğŸ”§ ä½¿ç”¨çš„ä¸»è¦æ”¹è¿›:\")\n",
    "        print(f\"  âœ… åŒä¸‰è§’ROI: é¢ˆéƒ¨ä¸Šæ–¹ + èƒ¸å£ä¸‹æ–¹è¦†ç›–\")\n",
    "        print(f\"  âœ… è‚¤è‰²å…ˆéªŒ: åŸºäºé¢éƒ¨è‡ªé€‚åº”è‚¤è‰²è¿‡æ»¤\")\n",
    "        print(f\"  âœ… å­ä¸‰è§’é€‰æ‹©: æ™ºèƒ½é€‰æ‹©å±‚å Vé¢†å°å€’ä¸‰è§’\")\n",
    "        print(f\"  âœ… å¤šäººæ”¯æŒ: è‡ªåŠ¨æ£€æµ‹å¤„ç†å¤šä¸ªäººå¹¶åˆå¹¶æ©è†œ\")\n",
    "\n",
    "    else:\n",
    "        print(f\"âŒ æ¼”ç¤ºå¤„ç†å¤±è´¥: {results.get('reason', 'unknown')}\")\n",
    "        if results.get('reason') == 'no_person_detected':\n",
    "            print(\"æç¤º: å›¾åƒä¸­æœªæ£€æµ‹åˆ°äººï¼Œè¯·å°è¯•å…¶ä»–å›¾åƒæˆ–è°ƒä½pose_confå‚æ•°\")\n",
    "\n",
    "else:\n",
    "    print(\"æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾åƒï¼Œè¯·å…ˆä¸Šä¼ å›¾åƒåˆ° data/ ç›®å½•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzWghQbl9ars"
   },
   "source": [
    "## 11. æ‰¹é‡å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFG2JPm09ars"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def batch_process(data_dir, output_dir, mode='both'):\n",
    "    \"\"\"æ‰¹é‡å¤„ç†å›¾åƒ\n",
    "\n",
    "    Args:\n",
    "        data_dir: è¾“å…¥ç›®å½•\n",
    "        output_dir: è¾“å‡ºç›®å½•\n",
    "        mode: å¤„ç†æ¨¡å¼\n",
    "    \"\"\"\n",
    "    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(list(Path(data_dir).glob(f'*{ext}')))\n",
    "        image_files.extend(list(Path(data_dir).glob(f'*{ext.upper()}')))\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶\")\n",
    "        return\n",
    "\n",
    "    print(f\"å¼€å§‹æ‰¹é‡å¤„ç† {len(image_files)} ä¸ªå›¾åƒ...\")\n",
    "    print(f\"è¾“å…¥ç›®å½•: {data_dir}\")\n",
    "    print(f\"è¾“å‡ºç›®å½•: {output_dir}\")\n",
    "    print(f\"å¤„ç†æ¨¡å¼: {mode}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    start_time = time.time()\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    failure_reasons = {}\n",
    "\n",
    "    for i, image_path in enumerate(image_files, 1):\n",
    "        print(f\"\\n[{i}/{len(image_files)}] \", end=\"\")\n",
    "\n",
    "        success, results = process_one(image_path, Path(output_dir), mode)\n",
    "\n",
    "        if success:\n",
    "            success_count += 1\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            reason = results.get('reason', 'unknown')\n",
    "            failure_reasons[reason] = failure_reasons.get(reason, 0) + 1\n",
    "\n",
    "    # ç»Ÿè®¡ç»“æœ\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    avg_time = total_time / len(image_files)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"æ‰¹å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"æ€»è€—æ—¶: {total_time:.2f}ç§’\")\n",
    "    print(f\"å¹³å‡è€—æ—¶: {avg_time:.2f}ç§’/å›¾åƒ\")\n",
    "    print(f\"æˆåŠŸå¤„ç†: {success_count}/{len(image_files)} ({success_count/len(image_files)*100:.1f}%)\")\n",
    "    print(f\"å¤±è´¥æ•°é‡: {failure_count}\")\n",
    "\n",
    "    if failure_reasons:\n",
    "        print(\"\\nå¤±è´¥åŸå› ç»Ÿè®¡:\")\n",
    "        for reason, count in failure_reasons.items():\n",
    "            print(f\"  - {reason}: {count}æ¬¡\")\n",
    "\n",
    "    # è¾“å‡ºæ–‡ä»¶ç»Ÿè®¡\n",
    "    output_files = list(Path(output_dir).glob('*'))\n",
    "    print(f\"\\nè¾“å‡ºæ–‡ä»¶: {len(output_files)}ä¸ª\")\n",
    "    print(f\"è¾“å‡ºç›®å½•: {Path(output_dir).absolute()}\")\n",
    "\n",
    "# æ‰§è¡Œæ‰¹å¤„ç†\n",
    "batch_process(\n",
    "    CONFIG['paths']['data_dir'],\n",
    "    CONFIG['paths']['out_dir'],\n",
    "    mode='both'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN3_SbKV9ars"
   },
   "source": [
    "## 12. ä¸€é”®è¿è¡Œå•å…ƒæ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atXnalKB9ars"
   },
   "outputs": [],
   "source": [
    "# ä¸€é”®è¿è¡Œï¼šæ¸…ç†è¾“å‡ºç›®å½•å¹¶é‡æ–°å¤„ç†æ‰€æœ‰å›¾åƒ\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def one_click_run():\n",
    "    \"\"\"ä¸€é”®è¿è¡Œå…¨éƒ¨æµç¨‹\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹ä¸€é”®è¿è¡Œæµç¨‹...\")\n",
    "\n",
    "    # 1. æ¸…ç†è¾“å‡ºç›®å½•\n",
    "    output_dir = Path(CONFIG['paths']['out_dir'])\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir(parents=True)\n",
    "    print(f\"âœ… å·²æ¸…ç†è¾“å‡ºç›®å½•: {output_dir}\")\n",
    "\n",
    "    # 2. æ£€æŸ¥è¾“å…¥æ–‡ä»¶\n",
    "    data_dir = Path(CONFIG['paths']['data_dir'])\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(list(data_dir.glob(f'*{ext}')))\n",
    "        image_files.extend(list(data_dir.glob(f'*{ext.upper()}')))\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°è¾“å…¥å›¾åƒæ–‡ä»¶\")\n",
    "        print(f\"è¯·å°†å›¾åƒæ–‡ä»¶æ”¾å…¥: {data_dir.absolute()}\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“ æ‰¾åˆ° {len(image_files)} ä¸ªè¾“å…¥å›¾åƒ\")\n",
    "\n",
    "    # 3. æ‰¹é‡å¤„ç†\n",
    "    batch_process(\n",
    "        CONFIG['paths']['data_dir'],\n",
    "        CONFIG['paths']['out_dir'],\n",
    "        mode='both'\n",
    "    )\n",
    "\n",
    "    # 4. ç”Ÿæˆç¼©ç•¥å›¾å¯¹æ¯”\n",
    "    create_summary_visualization()\n",
    "\n",
    "    print(\"\\nğŸ‰ ä¸€é”®è¿è¡Œå®Œæˆï¼\")\n",
    "\n",
    "def create_summary_visualization():\n",
    "    \"\"\"åˆ›å»ºç»“æœæ±‡æ€»å¯è§†åŒ–\"\"\"\n",
    "    output_dir = Path(CONFIG['paths']['out_dir'])\n",
    "\n",
    "    # æ‰¾åˆ°æ‰€æœ‰å¤„ç†ç»“æœ\n",
    "    original_files = list(Path(CONFIG['paths']['data_dir']).glob('*.jpg')) + \\\n",
    "                    list(Path(CONFIG['paths']['data_dir']).glob('*.jpeg')) + \\\n",
    "                    list(Path(CONFIG['paths']['data_dir']).glob('*.png'))\n",
    "\n",
    "    mosaic_files = list(output_dir.glob('*_mosaic.jpg'))\n",
    "    fill_files = list(output_dir.glob('*_fill.jpg'))\n",
    "\n",
    "    if len(mosaic_files) == 0 and len(fill_files) == 0:\n",
    "        print(\"æ²¡æœ‰æ‰¾åˆ°å¤„ç†ç»“æœ\")\n",
    "        return\n",
    "\n",
    "    # åˆ›å»ºå¯¹æ¯”å›¾\n",
    "    n_samples = min(3, len(original_files))  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ ·æœ¬\n",
    "\n",
    "    if n_samples > 0:\n",
    "        fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5*n_samples))\n",
    "        if n_samples == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            stem = original_files[i].stem\n",
    "\n",
    "            # åŸå›¾\n",
    "            try:\n",
    "                orig = cv2.imread(str(original_files[i]))\n",
    "                orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "                axes[i, 0].imshow(orig)\n",
    "                axes[i, 0].set_title(f'åŸå›¾: {original_files[i].name}')\n",
    "                axes[i, 0].axis('off')\n",
    "            except:\n",
    "                axes[i, 0].text(0.5, 0.5, 'æ— æ³•åŠ è½½', ha='center', va='center')\n",
    "                axes[i, 0].axis('off')\n",
    "\n",
    "            # é©¬èµ›å…‹ç»“æœ\n",
    "            mosaic_path = output_dir / f\"{stem}_mosaic.jpg\"\n",
    "            if mosaic_path.exists():\n",
    "                try:\n",
    "                    mosaic = cv2.imread(str(mosaic_path))\n",
    "                    mosaic = cv2.cvtColor(mosaic, cv2.COLOR_BGR2RGB)\n",
    "                    axes[i, 1].imshow(mosaic)\n",
    "                    axes[i, 1].set_title('é©¬èµ›å…‹å¤„ç†')\n",
    "                except:\n",
    "                    axes[i, 1].text(0.5, 0.5, 'æ— æ³•åŠ è½½', ha='center', va='center')\n",
    "            else:\n",
    "                axes[i, 1].text(0.5, 0.5, 'æ— ç»“æœ', ha='center', va='center')\n",
    "            axes[i, 1].axis('off')\n",
    "\n",
    "            # é¢œè‰²å¡«å……ç»“æœ\n",
    "            fill_path = output_dir / f\"{stem}_fill.jpg\"\n",
    "            if fill_path.exists():\n",
    "                try:\n",
    "                    fill = cv2.imread(str(fill_path))\n",
    "                    fill = cv2.cvtColor(fill, cv2.COLOR_BGR2RGB)\n",
    "                    axes[i, 2].imshow(fill)\n",
    "                    axes[i, 2].set_title('é¢œè‰²å¡«å……')\n",
    "                except:\n",
    "                    axes[i, 2].text(0.5, 0.5, 'æ— æ³•åŠ è½½', ha='center', va='center')\n",
    "            else:\n",
    "                axes[i, 2].text(0.5, 0.5, 'æ— ç»“æœ', ha='center', va='center')\n",
    "            axes[i, 2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('å¤„ç†ç»“æœæ±‡æ€»', fontsize=16, y=0.98)\n",
    "        plt.show()\n",
    "\n",
    "# æ‰§è¡Œä¸€é”®è¿è¡Œ\n",
    "one_click_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXswQoBx9art"
   },
   "source": [
    "## 13. å‚æ•°è°ƒæ•´åŒº\n",
    "\n",
    "### å¯è°ƒæ•´çš„å…³é”®å‚æ•°\n",
    "\n",
    "| å‚æ•° | é»˜è®¤å€¼ | å»ºè®®èŒƒå›´ | è¯´æ˜ |\n",
    "|------|--------|----------|------|\n",
    "| **åŸæœ‰å‚æ•°** |\n",
    "| roi_chest_down_ratio | 0.28 | 0.2-0.4 | èƒ¸å£å‚è€ƒç‚¹ä¸‹ç§»æ¯”ä¾‹ï¼Œè¶Šå¤§ä¸‰è§’å½¢è¶Šå°– |\n",
    "| shoulder_inset_ratio | 0.15 | 0.1-0.25 | è‚©ç‚¹å†…æ”¶æ¯”ä¾‹ï¼Œè¶Šå¤§ä¸‰è§’å½¢è¶Šçª„ |\n",
    "| mosaic_block | 14 | 8-24 | é©¬èµ›å…‹å—å¤§å°ï¼Œè¶Šå¤§è¶Šæ¨¡ç³Š |\n",
    "| blur_kernel | 21 | 15-31 | é«˜æ–¯æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼‰ |\n",
    "| dilate_for_sampling | 5 | 3-10 | è¡£ç‰©é‡‡æ ·è†¨èƒ€åŠå¾„ |\n",
    "| **æ–°å¢å‚æ•°ï¼šåŒä¸‰è§’ROI** |\n",
    "| neck_up_ratio | 0.12 | 0.08-0.2 | é¢ˆéƒ¨å‘ä¸Šä¸‰è§’æ¯”ä¾‹ï¼Œè¦†ç›–è‚©çº¿ä¸Šæ–¹Vé¢† |\n",
    "| **æ–°å¢å‚æ•°ï¼šè‚¤è‰²å…ˆéªŒ** |\n",
    "| color_thresh | 4.0 | 2.0-6.0 | è‚¤è‰²é©¬æ°è·ç¦»é˜ˆå€¼ï¼Œè¶Šå°è¶Šä¸¥æ ¼ |\n",
    "| **æ–°å¢å‚æ•°ï¼šå­ä¸‰è§’é€‰æ‹©** |\n",
    "| min_area_px | 20 | 10-50 | å­ä¸‰è§’æœ€å°é¢ç§¯(åƒç´ ) |\n",
    "| max_area_ratio | 0.03 | 0.01-0.08 | å­ä¸‰è§’æœ€å¤§é¢ç§¯æ¯”ä¾‹ |\n",
    "| prefer_up_or_down | 'auto' | 'up'/'down'/'auto' | å­ä¸‰è§’åå¥½æ–¹å‘ |\n",
    "| **æ–°å¢å‚æ•°ï¼šæ£€æµ‹** |\n",
    "| pose_conf | 0.25 | 0.1-0.5 | å…³é”®ç‚¹æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ |\n",
    "\n",
    "### å®éªŒä¸åŒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rwgrzNV9art"
   },
   "outputs": [],
   "source": [
    "# å‚æ•°å®éªŒåŒº - ä¿®æ”¹è¿™é‡Œçš„å‚æ•°å¹¶é‡æ–°è¿è¡Œå¤„ç†\n",
    "EXPERIMENTAL_CONFIG = {\n",
    "    # åŸæœ‰å‚æ•°\n",
    "    'roi_chest_down_ratio': 0.3,    # å¢å¤§ -> ä¸‰è§’å½¢æ›´å°–\n",
    "    'shoulder_inset_ratio': 0.2,     # å¢å¤§ -> ä¸‰è§’å½¢æ›´çª„\n",
    "    'mosaic_block': 16,              # å¢å¤§ -> é©¬èµ›å…‹æ›´ç²—\n",
    "    'blur_kernel': 25,               # å¢å¤§ -> æ¨¡ç³Šæ›´å¼ºï¼ˆéœ€è¦å¥‡æ•°ï¼‰\n",
    "    'dilate_for_sampling': 7,        # å¢å¤§ -> é‡‡æ ·æ›´å¤šè¡£ç‰©é¢œè‰²\n",
    "\n",
    "    # æ–°å¢å‚æ•°ï¼šåŒä¸‰è§’ROI\n",
    "    'neck_up_ratio': 0.15,           # å¢å¤§ -> é¢ˆéƒ¨ä¸‰è§’è¦†ç›–æ›´å¤šè‚©çº¿ä¸Šæ–¹åŒºåŸŸ\n",
    "\n",
    "    # æ–°å¢å‚æ•°ï¼šè‚¤è‰²å…ˆéªŒ\n",
    "    'color_thresh': 3.5,             # å‡å° -> æ›´ä¸¥æ ¼çš„è‚¤è‰²è¿‡æ»¤\n",
    "\n",
    "    # æ–°å¢å‚æ•°ï¼šå­ä¸‰è§’é€‰æ‹©\n",
    "    'min_area_px': 25,               # å¢å¤§ -> è¿‡æ»¤æ›´å°çš„ä¸‰è§’\n",
    "    'max_area_ratio': 0.025,         # å‡å° -> åªä¿ç•™ç›¸å¯¹æ›´å°çš„ä¸‰è§’\n",
    "    'prefer_up_or_down': 'down',     # åå¥½èƒ¸å£å‘ä¸‹çš„ä¸‰è§’\n",
    "\n",
    "    # æ–°å¢å‚æ•°ï¼šæ£€æµ‹\n",
    "    'pose_conf': 0.3,                # å¢å¤§ -> æ›´é«˜çš„æ£€æµ‹ç½®ä¿¡åº¦è¦æ±‚\n",
    "}\n",
    "\n",
    "def experiment_with_params(image_path, params):\n",
    "    \"\"\"ä½¿ç”¨å®éªŒå‚æ•°å¤„ç†å•å¼ å›¾åƒ\"\"\"\n",
    "    # ä¸´æ—¶æ›´æ–°é…ç½®\n",
    "    original_config = CONFIG['processing'].copy()\n",
    "    CONFIG['processing'].update(params)\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ§ª å®éªŒå‚æ•°: {params}\")\n",
    "        success, results = process_one(\n",
    "            image_path,\n",
    "            Path(CONFIG['paths']['out_dir']) / 'experiment',\n",
    "            mode='both'\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            print(\"âœ… å®éªŒå¤„ç†æˆåŠŸ\")\n",
    "            print(f\"   å¤„ç†äººæ•°: {results.get('processed_count', 0)}/{results.get('total_persons', 0)}\")\n",
    "            return results\n",
    "        else:\n",
    "            print(f\"âŒ å®éªŒå¤„ç†å¤±è´¥: {results}\")\n",
    "            return None\n",
    "\n",
    "    finally:\n",
    "        # æ¢å¤åŸå§‹é…ç½®\n",
    "        CONFIG['processing'] = original_config\n",
    "\n",
    "# åˆ›å»ºå®éªŒè¾“å‡ºç›®å½•\n",
    "exp_dir = Path(CONFIG['paths']['out_dir']) / 'experiment'\n",
    "exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# å¦‚æœæœ‰å›¾åƒæ–‡ä»¶ï¼Œç”¨ç¬¬ä¸€ä¸ªè¿›è¡Œå®éªŒ\n",
    "if image_files:\n",
    "    print(\"ğŸ§ª å¼€å§‹å¤šäººåŒä¸‰è§’ROIå‚æ•°å®éªŒ...\")\n",
    "    exp_results = experiment_with_params(image_files[0], EXPERIMENTAL_CONFIG)\n",
    "\n",
    "    if exp_results:\n",
    "        print(f\"å®éªŒç»“æœä¿å­˜åœ¨: {exp_dir}\")\n",
    "        print(\"ğŸ“Š ä¸»è¦æ”¹è¿›ï¼š\")\n",
    "        print(\"  - åŒä¸‰è§’ROIï¼šè¦†ç›–è‚©çº¿ä¸Šæ–¹å’Œèƒ¸å£å‘ä¸‹åŒºåŸŸ\")\n",
    "        print(\"  - è‚¤è‰²å…ˆéªŒï¼šè‡ªåŠ¨è¿‡æ»¤è¡£ç‰©è¿‘è‰²è¯¯æ£€\")\n",
    "        print(\"  - å­ä¸‰è§’é€‰æ‹©ï¼šæ™ºèƒ½é€‰æ‹©å±‚å Vé¢†çš„å°å€’ä¸‰è§’\")\n",
    "        print(\"  - å¤šäººæ”¯æŒï¼šè‡ªåŠ¨å¤„ç†å›¾åƒä¸­çš„å¤šä¸ªäºº\")\n",
    "else:\n",
    "    print(\"æ²¡æœ‰å›¾åƒæ–‡ä»¶ç”¨äºå®éªŒ\")\n",
    "\n",
    "print(\"\\nğŸ’¡ æç¤º: ä¿®æ”¹ä¸Šé¢çš„ EXPERIMENTAL_CONFIG å‚æ•°å¹¶é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼æ¥æµ‹è¯•ä¸åŒæ•ˆæœ\")\n",
    "print(\"ğŸ”§ é‡ç‚¹è°ƒæ•´å‚æ•°ï¼šneck_up_ratioï¼ˆé¢ˆéƒ¨è¦†ç›–ï¼‰ã€color_threshï¼ˆè‚¤è‰²ä¸¥æ ¼åº¦ï¼‰ã€prefer_up_or_downï¼ˆä¸‰è§’åå¥½ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKPFylt09art"
   },
   "source": [
    "## 14. æ•…éšœè¯Šæ–­ä¸é™çº§å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mfT-J729art"
   },
   "outputs": [],
   "source": [
    "def system_diagnosis():\n",
    "    \"\"\"ç³»ç»Ÿè¯Šæ–­\"\"\"\n",
    "    print(\"ğŸ” ç³»ç»Ÿè¯Šæ–­æŠ¥å‘Š\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # 1. ç¯å¢ƒæ£€æŸ¥\n",
    "    print(\"\\n1. ç¯å¢ƒæ£€æŸ¥:\")\n",
    "    print(f\"   Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"   PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "        print(f\"   CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"   GPUè®¾å¤‡: {torch.cuda.get_device_name()}\")\n",
    "    except ImportError:\n",
    "        print(\"   âŒ PyTorchæœªæ­£ç¡®å®‰è£…\")\n",
    "\n",
    "    try:\n",
    "        import cv2\n",
    "        print(f\"   OpenCVç‰ˆæœ¬: {cv2.__version__}\")\n",
    "    except ImportError:\n",
    "        print(\"   âŒ OpenCVæœªæ­£ç¡®å®‰è£…\")\n",
    "\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        print(f\"   Ultralyticså¯ç”¨: âœ…\")\n",
    "    except ImportError:\n",
    "        print(\"   âŒ Ultralyticsæœªæ­£ç¡®å®‰è£…\")\n",
    "\n",
    "    # 2. æ¨¡å‹çŠ¶æ€\n",
    "    print(\"\\n2. æ¨¡å‹çŠ¶æ€:\")\n",
    "    if 'pose_model' in globals():\n",
    "        print(\"   YOLOv8-Pose: âœ… å·²åŠ è½½\")\n",
    "    else:\n",
    "        print(\"   YOLOv8-Pose: ğŸ”„ æœªåŠ è½½ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åŠ è½½ï¼‰\")\n",
    "\n",
    "    if 'sam2_predictor' in globals():\n",
    "        if sam2_predictor is not None:\n",
    "            print(\"   SAM2: âœ… å·²åŠ è½½\")\n",
    "        else:\n",
    "            print(\"   SAM2: âŒ åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ\")\n",
    "    else:\n",
    "        print(\"   SAM2: ğŸ”„ æœªåŠ è½½ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åŠ è½½ï¼‰\")\n",
    "\n",
    "    # 3. ç›®å½•çŠ¶æ€\n",
    "    print(\"\\n3. ç›®å½•çŠ¶æ€:\")\n",
    "    data_dir = Path(CONFIG['paths']['data_dir'])\n",
    "    output_dir = Path(CONFIG['paths']['out_dir'])\n",
    "\n",
    "    print(f\"   æ•°æ®ç›®å½•: {data_dir} {'âœ…' if data_dir.exists() else 'âŒ ä¸å­˜åœ¨'}\")\n",
    "    print(f\"   è¾“å‡ºç›®å½•: {output_dir} {'âœ…' if output_dir.exists() else 'âŒ ä¸å­˜åœ¨'}\")\n",
    "\n",
    "    # ç»Ÿè®¡æ–‡ä»¶æ•°é‡\n",
    "    if data_dir.exists():\n",
    "        image_count = len([f for f in data_dir.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']])\n",
    "        print(f\"   è¾“å…¥å›¾åƒæ•°é‡: {image_count}\")\n",
    "\n",
    "    if output_dir.exists():\n",
    "        output_count = len(list(output_dir.glob('*')))\n",
    "        print(f\"   è¾“å‡ºæ–‡ä»¶æ•°é‡: {output_count}\")\n",
    "\n",
    "    # 4. å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ\n",
    "    print(\"\\n4. å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ:\")\n",
    "    print(\"   - å¦‚æœSAM2åŠ è½½å¤±è´¥: å°†ä½¿ç”¨ç®€åŒ–åˆ†å‰²æ–¹æ¡ˆ\")\n",
    "    print(\"   - å¦‚æœæœªæ£€æµ‹åˆ°è‚©ç‚¹: æ£€æŸ¥å›¾åƒä¸­äººä½“å§¿æ€æ˜¯å¦æ¸…æ™°\")\n",
    "    print(\"   - å¦‚æœå¤„ç†å¾ˆæ…¢: è€ƒè™‘ä½¿ç”¨æ›´å°çš„å›¾åƒæˆ–å‡å°‘batch size\")\n",
    "    print(\"   - å¦‚æœå†…å­˜ä¸è¶³: è®¾ç½® CONFIG['runtime']['device'] = 'cpu'\")\n",
    "\n",
    "    print(\"\\nâœ… è¯Šæ–­å®Œæˆ\")\n",
    "\n",
    "# è¿è¡Œè¯Šæ–­\n",
    "system_diagnosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZEskSfd9art"
   },
   "source": [
    "## 15. å¯¼å‡ºä¸å‘½ä»¤è¡Œä½¿ç”¨\n",
    "\n",
    "### å°†Notebookå¯¼å‡ºä¸ºPythonè„šæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmdjqju-9art"
   },
   "outputs": [],
   "source": [
    "def export_to_script():\n",
    "    \"\"\"å¯¼å‡ºæ ¸å¿ƒåŠŸèƒ½ä¸ºPythonè„šæœ¬\"\"\"\n",
    "    script_content = '''#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Vå½¢é¢†ä¸‰è§’çš®è‚¤æ£€æµ‹ä¸å±€éƒ¨æ‰“ç ç³»ç»Ÿ - å‘½ä»¤è¡Œç‰ˆæœ¬\n",
    "\n",
    "ä» vneck_skin_censor.ipynb å¯¼å‡º\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è¿™é‡Œä¼šåŒ…å«æ‰€æœ‰æ ¸å¿ƒå‡½æ•°çš„å®šä¹‰...\n",
    "# (ç”±äºé•¿åº¦é™åˆ¶ï¼Œè¿™é‡Œåªå±•ç¤ºæ¡†æ¶)\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Vå½¢é¢†çš®è‚¤æ£€æµ‹ä¸å¤„ç†')\n",
    "    parser.add_argument('input', help='è¾“å…¥å›¾åƒè·¯å¾„æˆ–ç›®å½•')\n",
    "    parser.add_argument('--output', '-o', default='./outputs', help='è¾“å‡ºç›®å½•')\n",
    "    parser.add_argument('--mode', choices=['mosaic', 'fill', 'both'], default='both', help='å¤„ç†æ¨¡å¼')\n",
    "    parser.add_argument('--device', choices=['cuda', 'cpu', 'auto'], default='auto', help='è®¾å¤‡é€‰æ‹©')\n",
    "    parser.add_argument('--block-size', type=int, default=14, help='é©¬èµ›å…‹å—å¤§å°')\n",
    "    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # å¤„ç†é€»è¾‘...\n",
    "    print(f\"è¾“å…¥: {args.input}\")\n",
    "    print(f\"è¾“å‡º: {args.output}\")\n",
    "    print(f\"æ¨¡å¼: {args.mode}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "\n",
    "    script_path = Path('vneck_skin_censor.py')\n",
    "    with open(script_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(script_content)\n",
    "\n",
    "    print(f\"âœ… è„šæœ¬å·²å¯¼å‡ºä¸º: {script_path.absolute()}\")\n",
    "    print(\"\\nä½¿ç”¨æ–¹æ³•:\")\n",
    "    print(\"  python vneck_skin_censor.py image.jpg --output ./results --mode both\")\n",
    "    print(\"  python vneck_skin_censor.py ./data --output ./results --mode mosaic\")\n",
    "\n",
    "# å¯¼å‡ºè„šæœ¬\n",
    "export_to_script()\n",
    "\n",
    "print(\"\\nğŸ“– å®Œæ•´çš„è„šæœ¬å¯¼å‡ºéœ€è¦å°†Notebookä¸­çš„æ‰€æœ‰å‡½æ•°å®šä¹‰å¤åˆ¶åˆ°è„šæœ¬ä¸­\")\n",
    "print(\"å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†Notebookè½¬æ¢ä¸ºå®Œæ•´çš„Pythonè„šæœ¬:\")\n",
    "print(\"  jupyter nbconvert --to python vneck_skin_censor.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiswFJL29art"
   },
   "source": [
    "## 16. æ€»ç»“ä¸è¯´æ˜\n",
    "\n",
    "### åŠŸèƒ½ç‰¹æ€§\n",
    "\n",
    "âœ… **å®Œæ•´ç®¡çº¿**: å…³é”®ç‚¹æ£€æµ‹ â†’ ROIæ„é€  â†’ è¯­ä¹‰åˆ†å‰² â†’ SAM2ç²¾ç¡®åˆ†å‰² â†’ å›¾åƒå¤„ç†\n",
    "\n",
    "âœ… **åŒé‡å¤„ç†**: é©¬èµ›å…‹æ¨¡ç³Šå’Œè¡£ç‰©é¢œè‰²å¡«å……ä¸¤ç§æ¨¡å¼\n",
    "\n",
    "âœ… **æ‰¹é‡å¤„ç†**: æ”¯æŒæ–‡ä»¶å¤¹æ‰¹é‡å¤„ç†ï¼Œè‡ªåŠ¨åŒ–å·¥ä½œæµ\n",
    "\n",
    "âœ… **å®¹é”™è®¾è®¡**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶\n",
    "\n",
    "âœ… **å‚æ•°å¯è°ƒ**: é›†ä¸­é…ç½®ï¼Œä¾¿äºä¸åŒåœºæ™¯ä¼˜åŒ–\n",
    "\n",
    "âœ… **å¯è§†åŒ–**: å®Œæ•´çš„å¤„ç†è¿‡ç¨‹å¯è§†åŒ–å’Œç»“æœå±•ç¤º\n",
    "\n",
    "### æŠ€æœ¯äº®ç‚¹\n",
    "\n",
    "- **è‡ªé€‚åº”è®¾å¤‡**: è‡ªåŠ¨æ£€æµ‹CUDA/CPUå¹¶ä¼˜åŒ–é…ç½®\n",
    "- **æ¨¡å‹çƒ­åŠ è½½**: å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼ŒèŠ‚çœå¯åŠ¨æ—¶é—´\n",
    "- **HuggingFaceé›†æˆ**: æ”¯æŒé•œåƒç«™å’Œç¼“å­˜ç®¡ç†\n",
    "- **å›é€€ç­–ç•¥**: SAM2ä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨ç®€åŒ–åˆ†å‰²\n",
    "- **æ³Šæ¾èåˆ**: ä½¿ç”¨cv2.seamlessCloneå®ç°è‡ªç„¶çš„é¢œè‰²å¡«å……\n",
    "\n",
    "### ä½¿ç”¨å»ºè®®\n",
    "\n",
    "1. **é¦–æ¬¡è¿è¡Œ**: æ‰§è¡Œå®Œæ•´çš„ä¾èµ–å®‰è£…å’Œæ¨¡å‹ä¸‹è½½æµç¨‹\n",
    "2. **å‚æ•°è°ƒä¼˜**: æ ¹æ®å…·ä½“å›¾åƒç‰¹ç‚¹è°ƒæ•´ROIå’Œå¤„ç†å‚æ•°  \n",
    "3. **æ‰¹é‡å¤„ç†**: ä½¿ç”¨ä¸€é”®è¿è¡ŒåŠŸèƒ½å¤„ç†æ•´ä¸ªæ–‡ä»¶å¤¹\n",
    "4. **æ€§èƒ½ä¼˜åŒ–**: GPUç¯å¢ƒä¸‹å¼€å¯fp16ç²¾åº¦æ¨¡å¼\n",
    "5. **æ•…éšœæ’é™¤**: ä½¿ç”¨ç³»ç»Ÿè¯Šæ–­åŠŸèƒ½å®šä½é—®é¢˜\n",
    "\n",
    "### æ‰©å±•æ–¹å‘\n",
    "\n",
    "- é›†æˆæ›´å¤šè¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼ˆBiSeNet, DeepLabV3ç­‰ï¼‰\n",
    "- æ·»åŠ ONNX/TensorRTæ¨ç†åŠ é€Ÿ\n",
    "- å®ç°Streamlit Webç•Œé¢\n",
    "- æ”¯æŒè§†é¢‘å¤„ç†\n",
    "- æ·»åŠ æ›´å¤šå›¾åƒä¿®å¤ç®—æ³•\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ¯ éªŒæ”¶æ ‡å‡†å®Œæˆæƒ…å†µ:**\n",
    "\n",
    "âœ… åœ¨æœ‰/æ— è§£ææ¨¡å—æ¡ä»¶ä¸‹æ­£å¸¸è¿è¡Œ  \n",
    "âœ… å¯¹å°ä¸‰è§’åŒºåŸŸæœ‰æ•ˆæ£€æµ‹  \n",
    "âœ… æ‰¹é‡å¤„ç†è¾“å‡ºè§„èŒƒåŒ–æ–‡ä»¶  \n",
    "âœ… ç»“æ„æ¸…æ™°ã€æ³¨é‡Šå®Œæ•´ã€å‚æ•°é›†ä¸­  \n",
    "âœ… å‹å¥½çš„é”™è¯¯å¤„ç†æœºåˆ¶  \n",
    "\n",
    "**ğŸš€ ç³»ç»Ÿå°±ç»ªï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "L4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "114937d028444a01b0b415c72b9a756d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FileUploadModel",
     "model_module_version": "1.5.0",
     "state": {
      "_counter": 0,
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FileUploadModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FileUploadView",
      "accept": "image/*",
      "button_style": "",
      "data": [],
      "description": "é€‰æ‹©å›¾åƒæ–‡ä»¶",
      "description_tooltip": null,
      "disabled": false,
      "error": "",
      "icon": "upload",
      "layout": "IPY_MODEL_f804620a9c674a3e9a272fee9a9fad0a",
      "metadata": [],
      "multiple": true,
      "style": "IPY_MODEL_fd90dde495114358933572347b2895d2"
     }
    },
    "f804620a9c674a3e9a272fee9a9fad0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd90dde495114358933572347b2895d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}